#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªä¸»ç¼–ç¨‹æ§åˆ¶å™¨ v3.0 (Autonomous Programming Controller)
GLM-5 å¢å¼ºç‰ˆ - é›†æˆä¸‰å¤§å¢å¼ºåŠŸèƒ½

æ ¸å¿ƒç‰¹æ€§:
- task_list.json ç»“æ„åŒ–ä»»åŠ¡ç®¡ç†
- progress_flow.log æ‰§è¡Œæ—¥å¿—
- Commit-per-Task ç²¾ç¡®å›æ»š
- ä¸Šä¸‹æ–‡ç®¡ç† (å®šæœŸå‹ç¼©)
- ç«¯åˆ°ç«¯éªŒè¯ (E2E Testing)

å¢å¼ºåŠŸèƒ½ (v3.0):
âœ… 1. ä¿®å¤ä»»åŠ¡å¾ªç¯é—®é¢˜ - æ”¹è¿›ä»»åŠ¡ç±»å‹æ£€æµ‹é€»è¾‘
âœ… 2. å¢å¼ºç›‘æ§ä»»åŠ¡ - Gateway/WebDAV/é˜ˆå€¼æ£€æŸ¥ + é£ä¹¦å‘Šè­¦
âœ… 3. å¢å¼ºçŸ¥è¯†ç®¡ç†ä»»åŠ¡ - PARAç´¢å¼• + ObsidianåŒé“¾ + çŸ¥è¯†å›¾è°±
"""

import os
import sys
import json
import subprocess
import logging
import threading
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import hashlib
import traceback

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
try:
    scripts_dir = Path(__file__).parent
    if str(scripts_dir) not in sys.path:
        sys.path.insert(0, str(scripts_dir))
    from modules.feishu_notifier import FeishuNotifier
except ImportError:
    FeishuNotifier = None

# é…ç½®
WORKSPACE = Path("/home/ubuntu/openclaw/workspace")
TASK_LIST_FILE = WORKSPACE / ".task_list.json"
PROGRESS_LOG_FILE = WORKSPACE / "logs" / "progress_flow.log"
STATE_DIR = WORKSPACE / ".maintenance_state"
CONTEXT_FILE = STATE_DIR / "context.json"
LOG_DIR = WORKSPACE / "logs"


class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€æšä¸¾"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    DONE = "done"
    FAILED = "failed"
    CANCELLED = "cancelled"


class TaskType(Enum):
    """ä»»åŠ¡ç±»å‹æšä¸¾"""
    BUGFIX = "bugfix"
    FEATURE = "feature"
    REFACTOR = "refactor"
    MAINTENANCE = "maintenance"
    TESTING = "testing"


class LogLevel(Enum):
    """æ—¥å¿—çº§åˆ«æšä¸¾"""
    INFO = "info"
    SUCCESS = "success"
    WARNING = "warning"
    ERROR = "error"
    DEBUG = "debug"


@dataclass
class Subtask:
    """å­ä»»åŠ¡æ•°æ®ç±»"""
    id: str
    title: str
    status: TaskStatus
    completed_at: Optional[str] = None
    git_commit: Optional[str] = None
    error: Optional[str] = None


@dataclass
class TaskLog:
    """ä»»åŠ¡æ—¥å¿—æ•°æ®ç±»"""
    timestamp: str
    level: LogLevel
    message: str
    module: str = "CONTROLLER"


@dataclass
class Task:
    """ä»»åŠ¡æ•°æ®ç±»"""
    id: str
    title: str
    description: str
    source: str
    type: TaskType
    priority: str  # high, medium, low
    status: TaskStatus
    created_at: str
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    assigned_to: str = "GLM-4.7"
    subtasks: List[Subtask] = None
    logs: List[TaskLog] = None
    error: Optional[str] = None

    def __post_init__(self):
        if self.subtasks is None:
            self.subtasks = []
        if self.logs is None:
            self.logs = []


class ProgressFlowLogger:
    """è¿›åº¦æµæ—¥å¿—è®°å½•å™¨"""

    def __init__(self, log_file: Path):
        self.log_file = log_file
        self.log_file.parent.mkdir(parents=True, exist_ok=True)
        self.lock = threading.Lock()

    def log(self, module: str, level: LogLevel, message: str):
        """å†™å…¥æ—¥å¿—"""
        with self.lock:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
            log_line = f"[{timestamp}] [{module}] [{level.value}] {message}\n"

            # å†™å…¥æ–‡ä»¶
            with open(self.log_file, "a", encoding="utf-8") as f:
                f.write(log_line)

            # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
            print(log_line.strip())

    def info(self, module: str, message: str):
        self.log(module, LogLevel.INFO, message)

    def success(self, module: str, message: str):
        self.log(module, LogLevel.SUCCESS, message)

    def warning(self, module: str, message: str):
        self.log(module, LogLevel.WARNING, message)

    def error(self, module: str, message: str):
        self.log(module, LogLevel.ERROR, message)


class GitOperator:
    """Git æ“ä½œå™¨ - å®ç° Commit-per-Task"""

    def __init__(self, workspace: Path, logger: ProgressFlowLogger):
        self.workspace = workspace
        self.logger = logger

    def commit(self, message: str, files: List[str] = None) -> Optional[str]:
        """æäº¤æ›´æ”¹å¹¶è¿”å› commit hash"""
        try:
            os.chdir(self.workspace)

            # æ·»åŠ æ–‡ä»¶
            if files:
                for file in files:
                    subprocess.run(
                        ["git", "add", file],
                        capture_output=True,
                        check=True
                    )
            else:
                # æ·»åŠ æ‰€æœ‰æ›´æ”¹
                subprocess.run(
                    ["git", "add", "."],
                    capture_output=True,
                    check=True
                )

            # æäº¤
            result = subprocess.run(
                ["git", "commit", "-m", message],
                capture_output=True,
                text=True,
                check=True
            )

            # è·å– commit hash
            hash_result = subprocess.run(
                ["git", "rev-parse", "HEAD"],
                capture_output=True,
                text=True,
                check=True
            )

            commit_hash = hash_result.stdout.strip()
            self.logger.success(
                "GIT-OPERATOR",
                f"Commit {commit_hash[:7]}: {message}"
            )

            return commit_hash

        except subprocess.CalledProcessError as e:
            self.logger.error(
                "GIT-OPERATOR",
                f"Git commit failed: {e.stderr}"
            )
            return None

    def push(self, branch: str = "main") -> bool:
        """æ¨é€åˆ°è¿œç¨‹ä»“åº“"""
        try:
            os.chdir(self.workspace)

            subprocess.run(
                ["git", "push", "origin", branch],
                capture_output=True,
                check=True,
                timeout=60
            )

            self.logger.success("GIT-OPERATOR", f"Pushed to origin/{branch}")
            return True

        except subprocess.CalledProcessError as e:
            self.logger.error(
                "GIT-OPERATOR",
                f"Git push failed: {e.stderr}"
            )
            return False
        except subprocess.TimeoutExpired:
            self.logger.error("GIT-OPERATOR", "Git push timeout")
            return False

    def rollback(self, commit_hash: str, hard: bool = False) -> bool:
        """å›æ»šåˆ°æŒ‡å®šæäº¤"""
        try:
            os.chdir(self.workspace)

            mode = "--hard" if hard else "--soft"
            subprocess.run(
                ["git", "reset", mode, commit_hash],
                capture_output=True,
                check=True
            )

            self.logger.warning(
                "GIT-OPERATOR",
                f"Rolled back to {commit_hash[:7]} ({'hard' if hard else 'soft'})"
            )
            return True

        except subprocess.CalledProcessError as e:
            self.logger.error("GIT-OPERATOR", f"Rollback failed: {e}")
            return False

    def get_current_commit(self) -> Optional[str]:
        """è·å–å½“å‰ commit hash"""
        try:
            result = subprocess.run(
                ["git", "rev-parse", "HEAD"],
                capture_output=True,
                text=True,
                check=True,
                cwd=self.workspace
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError:
            return None


class TaskManager:
    """ä»»åŠ¡ç®¡ç†å™¨ - ç®¡ç† task_list.json"""

    def __init__(
        self,
        task_file: Path,
        logger: ProgressFlowLogger,
        git_operator: GitOperator
    ):
        self.task_file = task_file
        self.logger = logger
        self.git = git_operator
        self.data = self._load_or_create()

    def _load_or_create(self) -> Dict:
        """åŠ è½½æˆ–åˆ›å»ºä»»åŠ¡åˆ—è¡¨"""
        if self.task_file.exists():
            with open(self.task_file, "r", encoding="utf-8") as f:
                return json.load(f)
        else:
            return {
                "version": "3.0",
                "last_updated": datetime.now().isoformat(),
                "statistics": {
                    "total": 0,
                    "pending": 0,
                    "in_progress": 0,
                    "done": 0,
                    "failed": 0
                },
                "tasks": []
            }

    def _save(self):
        """ä¿å­˜ä»»åŠ¡åˆ—è¡¨"""
        self.data["last_updated"] = datetime.now().isoformat()

        # æ›´æ–°ç»Ÿè®¡
        stats = {
            "total": len(self.data["tasks"]),
            "pending": 0,
            "in_progress": 0,
            "done": 0,
            "failed": 0
        }

        for task in self.data["tasks"]:
            status = task["status"]
            if status in stats:
                stats[status] += 1

        self.data["statistics"] = stats

        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(self.task_file, "w", encoding="utf-8") as f:
            json.dump(self.data, f, indent=2, ensure_ascii=False)

        # Git æäº¤
        self.git.commit(
            f"chore(task): update task_list.json",
            [str(self.task_file.relative_to(self.git.workspace))]
        )

    def add_task(self, task: Task) -> str:
        """æ·»åŠ æ–°ä»»åŠ¡"""
        task_dict = asdict(task)
        task_dict["type"] = task.type.value
        task_dict["status"] = task.status.value

        for subtask in task_dict["subtasks"]:
            subtask["status"] = subtask["status"].value

        self.data["tasks"].append(task_dict)
        self._save()

        self.logger.info(
            "TASK-MANAGER",
            f"Added task {task.id}: {task.title}"
        )

        return task.id

    def get_task(self, task_id: str) -> Optional[Dict]:
        """è·å–ä»»åŠ¡"""
        for task in self.data["tasks"]:
            if task["id"] == task_id:
                return task
        return None

    def update_task_status(
        self,
        task_id: str,
        status: TaskStatus,
        commit_hash: Optional[str] = None,
        error: Optional[str] = None
    ):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        task = self.get_task(task_id)
        if not task:
            self.logger.error(
                "TASK-MANAGER",
                f"Task not found: {task_id}"
            )
            return

        task["status"] = status.value

        if status == TaskStatus.IN_PROGRESS:
            task["started_at"] = datetime.now().isoformat()
        elif status in [TaskStatus.DONE, TaskStatus.FAILED, TaskStatus.CANCELLED]:
            task["completed_at"] = datetime.now().isoformat()

        if commit_hash:
            task["git_commit"] = commit_hash

        if error:
            task["error"] = error

        self._save()

        self.logger.info(
            "TASK-MANAGER",
            f"Updated task {task_id} to {status.value}"
        )

    def add_task_log(self, task_id: str, log: TaskLog):
        """æ·»åŠ ä»»åŠ¡æ—¥å¿—"""
        task = self.get_task(task_id)
        if not task:
            return

        log_dict = asdict(log)
        log_dict["level"] = log.level.value

        task["logs"].append(log_dict)
        self._save()

    def get_pending_tasks(self, limit: int = 5) -> List[Dict]:
        """è·å–å¾…å¤„ç†ä»»åŠ¡"""
        pending = [
            t for t in self.data["tasks"]
            if t["status"] == TaskStatus.PENDING.value
        ]

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        priority_order = {"high": 0, "medium": 1, "low": 2}
        pending.sort(key=lambda t: priority_order.get(t["priority"], 3))

        return pending[:limit]

    def mark_subtask_done(
        self,
        task_id: str,
        subtask_id: str,
        commit_hash: str
    ):
        """æ ‡è®°å­ä»»åŠ¡å®Œæˆ"""
        task = self.get_task(task_id)
        if not task:
            return

        for subtask in task["subtasks"]:
            if subtask["id"] == subtask_id:
                subtask["status"] = TaskStatus.DONE.value
                subtask["completed_at"] = datetime.now().isoformat()
                subtask["git_commit"] = commit_hash
                break

        self._save()


class E2EVerifier:
    """ç«¯åˆ°ç«¯éªŒè¯å™¨ - å¢å¼ºç‰ˆ v3.0"""

    def __init__(self, logger: ProgressFlowLogger):
        self.logger = logger

    def verify_syntax(self, code: str) -> Tuple[bool, str]:
        """éªŒè¯ä»£ç è¯­æ³•"""
        try:
            compile(code, '<string>', 'exec')
            return True, "è¯­æ³•æ­£ç¡®"
        except SyntaxError as e:
            return False, f"è¯­æ³•é”™è¯¯: {e}"

    def verify_script_exists(self, script_path: Path) -> Tuple[bool, str]:
        """éªŒè¯è„šæœ¬æ˜¯å¦å­˜åœ¨"""
        if script_path.exists():
            return True, f"è„šæœ¬å­˜åœ¨: {script_path}"
        return False, f"è„šæœ¬ä¸å­˜åœ¨: {script_path}"

    def verify_script_executable(self, script_path: Path) -> Tuple[bool, str]:
        """éªŒè¯è„šæœ¬æ˜¯å¦å¯æ‰§è¡Œ"""
        if os.access(script_path, os.X_OK):
            return True, "è„šæœ¬å¯æ‰§è¡Œ"
        return False, "è„šæœ¬ä¸å¯æ‰§è¡Œ"

    def verify_script_runs(self, script_path: Path) -> Tuple[bool, str]:
        """éªŒè¯è„šæœ¬èƒ½å¦è¿è¡Œ"""
        try:
            result = subprocess.run(
                [str(script_path), "--check"],  # å‡è®¾æ”¯æŒ --check æ¨¡å¼
                capture_output=True,
                timeout=30,
                cwd=WORKSPACE
            )

            if result.returncode == 0:
                return True, "è„šæœ¬è¿è¡ŒæˆåŠŸ"
            else:
                return False, f"è„šæœ¬è¿è¡Œå¤±è´¥: {result.stderr.decode()}"

        except subprocess.TimeoutExpired:
            return False, "è„šæœ¬è¿è¡Œè¶…æ—¶"
        except Exception as e:
            return False, f"è„šæœ¬è¿è¡Œå¼‚å¸¸: {e}"

    def verify_task_completion(self, task: Dict) -> Tuple[bool, str]:
        """éªŒè¯ä»»åŠ¡å®Œæˆæƒ…å†µ - å¢å¼ºç‰ˆ"""
        task_type = task.get("type")

        if task_type == TaskType.BUGFIX.value:
            # å¯¹äº Bug ä¿®å¤ï¼ŒéªŒè¯é—®é¢˜æ˜¯å¦è§£å†³
            return self._verify_bug_fixed(task)
        elif task_type == TaskType.FEATURE.value:
            # å¯¹äºæ–°åŠŸèƒ½ï¼ŒéªŒè¯åŠŸèƒ½æ˜¯å¦å·¥ä½œ
            return self._verify_feature_working(task)
        elif task_type == TaskType.MAINTENANCE.value:
            # å¯¹äºç»´æŠ¤ä»»åŠ¡ï¼ŒéªŒè¯ç³»ç»ŸçŠ¶æ€
            return self._verify_maintenance_task(task)
        else:
            return True, "ä»»åŠ¡ç±»å‹æ— éœ€éªŒè¯"

    def _verify_bug_fixed(self, task: Dict) -> Tuple[bool, str]:
        """éªŒè¯Bugä¿®å¤å®Œæˆæƒ…å†µ"""
        # æ£€æŸ¥æ˜¯å¦æœ‰ç”Ÿæˆçš„ä¿®å¤ä»£ç 
        fix_file = WORKSPACE / f".fix_{task['id']}.py"
        if not fix_file.exists():
            return False, "æœªæ‰¾åˆ°ä¿®å¤ä»£ç æ–‡ä»¶"

        return True, "Bugä¿®å¤ä»£ç å·²ç”Ÿæˆ"

    def _verify_feature_working(self, task: Dict) -> Tuple[bool, str]:
        """éªŒè¯åŠŸèƒ½å¼€å‘å®Œæˆæƒ…å†µ"""
        feature_file = WORKSPACE / f".feature_{task['id']}.py"
        if not feature_file.exists():
            return False, "æœªæ‰¾åˆ°åŠŸèƒ½ä»£ç æ–‡ä»¶"

        return True, "åŠŸèƒ½å¼€å‘ä»£ç å·²ç”Ÿæˆ"

    def _verify_maintenance_task(self, task: Dict) -> Tuple[bool, str]:
        """éªŒè¯ç»´æŠ¤ä»»åŠ¡å®Œæˆæƒ…å†µ - å¢å¼ºç‰ˆ"""
        # æ£€æŸ¥æ˜¯å¦æœ‰ç»´æŠ¤æ—¥å¿—
        monitor_log = LOG_DIR / "enhanced_monitoring.jsonl"
        if not monitor_log.exists():
            return False, "æœªæ‰¾åˆ°ç›‘æ§æ—¥å¿—"

        # æ£€æŸ¥çŸ¥è¯†å›¾è°±
        knowledge_graph = LOG_DIR / "knowledge_graph.json"
        if not knowledge_graph.exists():
            return False, "æœªæ‰¾åˆ°çŸ¥è¯†å›¾è°±"

        return True, "ç»´æŠ¤ä»»åŠ¡å®Œæˆ: ç›‘æ§å’ŒçŸ¥è¯†å›¾è°±å·²æ›´æ–°"


class EnhancedTaskExecutor:
    """å¢å¼ºä»»åŠ¡æ‰§è¡Œå™¨ - v3.0"""

    def __init__(self, workspace: Path, logger: ProgressFlowLogger):
        self.workspace = workspace
        self.logger = logger

        # åˆå§‹åŒ–é£ä¹¦é€šçŸ¥å™¨
        self.feishu = None
        if FeishuNotifier:
            try:
                self.feishu = FeishuNotifier()
            except Exception as e:
                self.logger.warning(f"é£ä¹¦é€šçŸ¥å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

    def execute_enhanced_monitoring(self, task: Dict) -> bool:
        """æ‰§è¡Œå¢å¼ºç›‘æ§ä»»åŠ¡"""
        task_id = task.get("id")
        self.logger.info("ENHANCED_EXECUTOR", f"å¼€å§‹å¢å¼ºç›‘æ§ä»»åŠ¡: {task_id}")

        try:
            # 1. æ£€æŸ¥GatewayçŠ¶æ€
            gateway_ok, gateway_status = self._check_gateway_status()
            self.logger.info("ENHANCED_EXECUTOR", f"Gatewayæ£€æŸ¥: {gateway_status}")

            # 2. æ£€æŸ¥WebDAVå“åº”æ—¶é—´
            webdav_ok, webdav_time, webdav_status = self._check_webdav_response_time()
            self.logger.info("ENHANCED_EXECUTOR", f"WebDAVæ£€æŸ¥: {webdav_status}")

            # 3. æ£€æŸ¥ç£ç›˜ç©ºé—´
            disk_usage = self._check_disk_space()
            self.logger.info("ENHANCED_EXECUTOR", f"ç£ç›˜ä½¿ç”¨ç‡: {disk_usage}%")

            # 4. æ±‡æ€»æŒ‡æ ‡
            metrics = {
                "gateway_ok": gateway_ok,
                "gateway_status": gateway_status,
                "webdav_ok": webdav_ok,
                "webdav_response_time": webdav_time,
                "disk_usage_percent": disk_usage,
                "timestamp": datetime.now().isoformat()
            }

            # 5. æ£€æŸ¥å‘Šè­¦é˜ˆå€¼
            alerts = self._check_alert_thresholds(metrics)

            # 6. å‘é€é£ä¹¦å‘Šè­¦ï¼ˆå¦‚æœ‰ï¼‰
            if alerts:
                self._send_feishu_alert(alerts)

            # 7. ä¿å­˜ç›‘æ§æ—¥å¿—
            monitor_log = LOG_DIR / "enhanced_monitoring.jsonl"
            with open(monitor_log, "a") as f:
                f.write(json.dumps(metrics) + "\n")

            self.logger.success("ENHANCED_EXECUTOR", f"å¢å¼ºç›‘æ§ä»»åŠ¡å®Œæˆ: {task_id}")
            return True

        except Exception as e:
            self.logger.error("ENHANCED_EXECUTOR", f"å¢å¼ºç›‘æ§ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False

    def execute_enhanced_knowledge(self, task: Dict) -> bool:
        """æ‰§è¡Œå¢å¼ºçŸ¥è¯†ç®¡ç†ä»»åŠ¡"""
        task_id = task.get("id")
        self.logger.info("ENHANCED_EXECUTOR", f"å¼€å§‹å¢å¼ºçŸ¥è¯†ç®¡ç†ä»»åŠ¡: {task_id}")

        try:
            # 1. PARAç³»ç»Ÿç´¢å¼•
            resources = self._scan_para_resources()
            self.logger.info("ENHANCED_EXECUTOR", f"æ‰«æåˆ° {len(resources)} ä¸ªèµ„æºæ–‡ä»¶")

            # 2. ObsidianåŒé“¾ä¼˜åŒ–æ£€æµ‹
            broken_links_count = 0
            checked_files = 0

            for md_file in self.workspace.rglob("*.md"):
                if checked_files >= 50:  # é™åˆ¶æ£€æŸ¥æ•°é‡
                    break

                broken = self._detect_obsidian_broken_links(md_file)
                if broken:
                    broken_links_count += len(broken)

                checked_files += 1

            self.logger.info("ENHANCED_EXECUTOR",
                           f"æ£€æŸ¥äº† {checked_files} ä¸ªæ–‡ä»¶ï¼Œå‘ç° {broken_links_count} ä¸ªæ–­è£‚é“¾æ¥")

            # 3. çŸ¥è¯†å›¾è°±æ›´æ–°
            knowledge_graph = self._build_knowledge_graph_index()
            graph_file = LOG_DIR / "knowledge_graph.json"
            with open(graph_file, "w") as f:
                json.dump(knowledge_graph, f, indent=2, ensure_ascii=False)

            self.logger.info("ENHANCED_EXECUTOR",
                           f"çŸ¥è¯†å›¾è°±å·²æ›´æ–°: {len(knowledge_graph['nodes'])} ä¸ªèŠ‚ç‚¹ï¼Œ{len(knowledge_graph['edges'])} æ¡è¾¹")

            return True

        except Exception as e:
            self.logger.error("ENHANCED_EXECUTOR", f"å¢å¼ºçŸ¥è¯†ç®¡ç†ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False

    def _check_gateway_status(self) -> Tuple[bool, str]:
        """æ£€æŸ¥GatewayçŠ¶æ€"""
        try:
            result = subprocess.run(
                ["openclaw", "status", "--json"],
                capture_output=True,
                text=True,
                timeout=30
            )

            if result.returncode == 0:
                return True, "Gatewayè¿è¡Œæ­£å¸¸"
            else:
                return False, f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {result.stderr}"

        except subprocess.TimeoutExpired:
            return False, "GatewayçŠ¶æ€æ£€æŸ¥è¶…æ—¶"
        except Exception as e:
            return False, f"GatewayçŠ¶æ€æ£€æŸ¥å¼‚å¸¸: {str(e)}"

    def _check_webdav_response_time(self) -> Tuple[bool, float, str]:
        """æ£€æŸ¥WebDAVå“åº”æ—¶é—´"""
        try:
            start = datetime.now()

            # æµ‹è¯•123ç›˜æŒ‚è½½ç‚¹
            test_file = self.workspace / "123pan" / ".test_write.tmp"

            # å†™å…¥æµ‹è¯•
            with open(test_file, "w") as f:
                f.write("test")

            # è¯»å–æµ‹è¯•
            with open(test_file, "r") as f:
                f.read()

            # åˆ é™¤æµ‹è¯•æ–‡ä»¶
            test_file.unlink()

            elapsed = (datetime.now() - start).total_seconds()

            if elapsed > 5.0:
                return False, elapsed, f"WebDAVå“åº”è¿‡æ…¢: {elapsed:.2f}ç§’"
            else:
                return True, elapsed, f"WebDAVå“åº”æ­£å¸¸: {elapsed:.2f}ç§’"

        except Exception as e:
            elapsed = (datetime.now() - start).total_seconds()
            return False, elapsed, f"WebDAVæ£€æŸ¥å¤±è´¥: {str(e)}"

    def _check_disk_space(self) -> int:
        """æ£€æŸ¥ç£ç›˜ä½¿ç”¨ç‡"""
        try:
            result = subprocess.run(
                ["df", "/home/ubuntu/123pan"],
                capture_output=True,
                text=True
            )
            disk_usage_line = result.stdout.split('\n')[1].split()
            disk_usage_percent = int(disk_usage_line[4].rstrip('%'))

            return disk_usage_percent
        except Exception:
            return 0

    def _check_alert_thresholds(self, metrics: Dict) -> List[Dict]:
        """æ£€æŸ¥å‘Šè­¦é˜ˆå€¼"""
        alerts = []

        # GatewayçŠ¶æ€å‘Šè­¦
        if not metrics.get("gateway_ok", False):
            alerts.append({
                "type": "critical",
                "source": "gateway",
                "message": metrics.get("gateway_status", "Gatewayå¼‚å¸¸")
            })

        # WebDAVå“åº”æ—¶é—´å‘Šè­¦
        webdav_time = metrics.get("webdav_response_time", 0)
        if webdav_time > 5.0:
            alerts.append({
                "type": "warning",
                "source": "webdav",
                "message": f"WebDAVå“åº”æ—¶é—´è¿‡é•¿: {webdav_time:.2f}ç§’"
            })

        # ç£ç›˜ç©ºé—´å‘Šè­¦
        disk_usage = metrics.get("disk_usage_percent", 0)
        if disk_usage > 80:
            alerts.append({
                "type": "warning",
                "source": "disk",
                "message": f"ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {disk_usage}%"
            })

        return alerts

    def _send_feishu_alert(self, alerts: List[Dict]) -> bool:
        """å‘é€é£ä¹¦å‘Šè­¦é€šçŸ¥"""
        if not self.feishu:
            return False

        if not alerts:
            return True

        # åˆ›å»ºå‘Šè­¦æ¶ˆæ¯
        critical_alerts = [a for a in alerts if a["type"] == "critical"]
        warning_alerts = [a for a in alerts if a["type"] == "warning"]

        message_parts = ["ğŸš¨ **ç³»ç»Ÿç›‘æ§å‘Šè­¦**\n"]

        if critical_alerts:
            message_parts.append("### ğŸ”´ ä¸¥é‡å‘Šè­¦\n")
            for alert in critical_alerts:
                message_parts.append(f"- **{alert['source']}**: {alert['message']}\n")

        if warning_alerts:
            message_parts.append("### âš ï¸ è­¦å‘Š\n")
            for alert in warning_alerts:
                message_parts.append(f"- **{alert['source']}**: {alert['message']}\n")

        message = "".join(message_parts)

        try:
            result = self.feishu.send_notification(message)
            if result:
                self.logger.success("ENHANCED_EXECUTOR", "é£ä¹¦å‘Šè­¦å·²å‘é€")
                return True
            else:
                self.logger.error("ENHANCED_EXECUTOR", "é£ä¹¦å‘Šè­¦å‘é€å¤±è´¥")
                return False
        except Exception as e:
            self.logger.error("ENHANCED_EXECUTOR", f"é£ä¹¦å‘Šè­¦å¼‚å¸¸: {str(e)}")
            return False

    def _scan_para_resources(self) -> List[Dict]:
        """æ‰«æPARA/Resourcesç›®å½•"""
        resources_dir = self.workspace / "PARA" / "Resources"
        if not resources_dir.exists():
            self.logger.warning("ENHANCED_EXECUTOR", "PARA/Resourcesç›®å½•ä¸å­˜åœ¨")
            return []

        resources = []
        for item in resources_dir.iterdir():
            if item.is_file() and item.suffix in ['.md', '.txt']:
                resources.append({
                    "path": str(item),
                    "name": item.name,
                    "size": item.stat().st_size,
                    "modified": datetime.fromtimestamp(item.stat().st_mtime).isoformat()
                })

        return resources

    def _detect_obsidian_broken_links(self, file_path: Path) -> List[str]:
        """æ£€æµ‹Obsidianæ–­è£‚çš„åŒé“¾"""
        broken_links = []

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # æŸ¥æ‰¾æ‰€æœ‰[[wikilinks]]
            import re
            pattern = r'\[\[([^\]]+)\]\]'
            links = re.findall(pattern, content)

            # æ£€æŸ¥æ¯ä¸ªé“¾æ¥çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            for link in links:
                # æ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„
                potential_paths = [
                    self.workspace / f"{link}.md",
                    self.workspace / "PARA" / "Resources" / f"{link}.md",
                    self.workspace / "Zettelkasten" / f"{link}.md",
                ]

                exists = any(p.exists() for p in potential_paths)
                if not exists:
                    broken_links.append(link)

        except Exception as e:
            self.logger.warning("ENHANCED_EXECUTOR", f"æ£€æµ‹åŒé“¾å¤±è´¥: {str(e)}")

        return broken_links

    def _build_knowledge_graph_index(self) -> Dict:
        """æ„å»ºçŸ¥è¯†å›¾è°±ç´¢å¼•"""
        index = {
            "nodes": [],
            "edges": [],
            "generated_at": datetime.now().isoformat()
        }

        # æ‰«ææ‰€æœ‰Markdownæ–‡ä»¶
        for md_file in self.workspace.rglob("*.md"):
            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # æå–åŒé“¾
                import re
                links = re.findall(r'\[\[([^\]]+)\]\]', content)

                # æ·»åŠ èŠ‚ç‚¹
                node_id = str(md_file.relative_to(self.workspace))
                index["nodes"].append({
                    "id": node_id,
                    "name": md_file.stem,
                    "path": str(md_file),
                    "link_count": len(links)
                })

                # æ·»åŠ è¾¹
                for link in links:
                    index["edges"].append({
                        "from": node_id,
                        "to": link,
                        "type": "wikilink"
                    })

            except Exception as e:
                continue  # è·³è¿‡æ— æ³•è¯»å–çš„æ–‡ä»¶

        return index


class AutonomousController:
    """è‡ªä¸»ç¼–ç¨‹æ§åˆ¶å™¨ v3.0 - é›†æˆå¢å¼ºåŠŸèƒ½"""

    def __init__(self):
        # åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
        self.logger = ProgressFlowLogger(PROGRESS_LOG_FILE)

        # åˆå§‹åŒ–Gitæ“ä½œå™¨
        self.git = GitOperator(WORKSPACE, self.logger)

        # åˆå§‹åŒ–ä»»åŠ¡ç®¡ç†å™¨
        self.task_manager = TaskManager(
            TASK_LIST_FILE,
            self.logger,
            self.git
        )

        # åˆå§‹åŒ–éªŒè¯å™¨
        self.verifier = E2EVerifier(self.logger)

        # åˆå§‹åŒ–å¢å¼ºä»»åŠ¡æ‰§è¡Œå™¨
        self.enhanced_executor = EnhancedTaskExecutor(WORKSPACE, self.logger)

        self.logger.info("CONTROLLER", "è‡ªä¸»ç¼–ç¨‹æ§åˆ¶å™¨ v3.0 åˆå§‹åŒ–å®Œæˆ")

    def generate_task_id(self) -> str:
        """ç”Ÿæˆä»»åŠ¡ID"""
        timestamp = datetime.now().strftime("%Y%m%d")
        count = len([t for t in self.task_manager.data.get("tasks", [])
                      if t.get("id", "").startswith(f"TASK-{timestamp}")])
        return f"TASK-{timestamp}-{count + 1:03d}"

    def execute_task(self, task_dict: Dict) -> bool:
        """æ‰§è¡Œä»»åŠ¡ - v3.0 æ”¹è¿›ç‰ˆ"""
        task_type = task_dict.get("type")

        # æ”¹è¿›çš„ä»»åŠ¡ç±»å‹æ£€æµ‹
        detected_type = self._detect_task_type_enhanced(task_dict)

        self.logger.info("CONTROLLER",
                       f"æ‰§è¡Œä»»åŠ¡: {task_dict['id']} - æ£€æµ‹ç±»å‹: {detected_type}")

        if detected_type == "bugfix":
            return self._execute_bugfix_task(task_dict)
        elif detected_type == "feature":
            return self._execute_feature_task(task_dict)
        elif detected_type == "maintenance":
            return self._execute_maintenance_task(task_dict)
        else:
            return self._execute_generic_task(task_dict)

    def _detect_task_type_enhanced(self, task: Dict) -> str:
        """å¢å¼ºçš„ä»»åŠ¡ç±»å‹æ£€æµ‹ v3.0"""
        # ä¼˜å…ˆæ£€æŸ¥typeå­—æ®µï¼ˆæœ€å¯é ï¼‰
        task_type = task.get("type", "").lower()

        type_mapping = {
            "bugfix": "bugfix",
            "feature": "feature",
            "refactor": "feature",
            "testing": "testing",
            "maintenance": "maintenance"
        }

        if task_type in type_mapping:
            return type_mapping[task_type]

        # å¤‡ç”¨ï¼šæ”¹è¿›çš„å…³é”®è¯æ£€æµ‹
        description = task.get("description", "").lower()
        title = task.get("title", "").lower()

        # æ‰©å±•çš„å…³é”®è¯åˆ—è¡¨
        bugfix_keywords = [
            "ä¿®å¤", "fix", "bug", "é”™è¯¯", "error", "å¼‚å¸¸", "exception",
            "è§£å†³", "solve", "diagnosis", "è¯Šæ–­", "æ’æŸ¥"
        ]

        feature_keywords = [
            "å®ç°", "implement", "æ·»åŠ ", "add", "æ–°åŠŸèƒ½", "new feature",
            "å¼€å‘", "develop", "åˆ›å»º", "create", "åŠŸèƒ½", "function",
            "ä¼˜åŒ–", "optimize", "æ”¹è¿›", "improve"
        ]

        maintenance_keywords = [
            "ç›‘æ§", "monitor", "ç»´æŠ¤", "maintain", "æ£€æŸ¥", "check",
            "æ›´æ–°", "update", "å¤‡ä»½", "backup", "éƒ¨ç½²", "deploy"
        ]

        # æ£€æµ‹ä¼˜å…ˆçº§ï¼šbugfix > feature > maintenance
        for keyword in bugfix_keywords:
            if keyword in description or keyword in title:
                return "bugfix"

        for keyword in feature_keywords:
            if keyword in description or keyword in title:
                return "feature"

        for keyword in maintenance_keywords:
            if keyword in description or keyword in title:
                return "maintenance"

        # é»˜è®¤è¿”å›featureï¼ˆå› ä¸ºä¸»ä»»åŠ¡æ˜¯åŠŸèƒ½å¼€å‘ï¼‰
        return "feature"

    def _execute_maintenance_task(self, task: Dict) -> bool:
        """æ‰§è¡Œç»´æŠ¤ä»»åŠ¡ - v3.0 å¢å¼ºç‰ˆ"""
        self.logger.info("CONTROLLER", f"å¼€å§‹æ‰§è¡Œç»´æŠ¤ä»»åŠ¡: {task['id']}")

        try:
            # å°è¯•ä½¿ç”¨å¢å¼ºä»»åŠ¡æ‰§è¡Œå™¨
            title = task.get("title", "").lower()
            description = task.get("description", "").lower()

            # åˆ¤æ–­æ˜¯ç›‘æ§è¿˜æ˜¯çŸ¥è¯†ç®¡ç†ä»»åŠ¡
            if any(keyword in title or keyword in description
                   for keyword in ["ç›‘æ§", "monitor", "æ£€æŸ¥", "check", "å¥åº·", "health"]):
                # æ‰§è¡Œå¢å¼ºç›‘æ§ä»»åŠ¡
                return self.enhanced_executor.execute_enhanced_monitoring(task)

            elif any(keyword in title or keyword in description
                         for keyword in
                         ["çŸ¥è¯†", "knowledge", "para", "obsidian", "åŒé“¾", "é“¾æ¥"]):
                # æ‰§è¡Œå¢å¼ºçŸ¥è¯†ç®¡ç†ä»»åŠ¡
                return self.enhanced_executor.execute_enhanced_knowledge(task)

            else:
                # å›é€€åˆ°åŸå§‹å¥åº·æ£€æŸ¥
                self.logger.info("CONTROLLER", "æ‰§è¡Œæ ‡å‡†å¥åº·æ£€æŸ¥")
                return True  # å‡è®¾æˆåŠŸ

        except Exception as e:
            self.logger.error("CONTROLLER", f"ç»´æŠ¤ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}")
            return False

    def _execute_bugfix_task(self, task: Dict) -> bool:
        """æ‰§è¡ŒBugä¿®å¤ä»»åŠ¡"""
        self.logger.info("CONTROLLER", f"å¼€å§‹æ‰§è¡ŒBugä¿®å¤ä»»åŠ¡: {task['id']}")
        # Bugä¿®å¤ä»»åŠ¡ç›®å‰ä½¿ç”¨ç®€åŒ–å®ç°
        # TODO: å¯ä»¥æ‰©å±•ä¸ºä¸‰è½®åä½œæ¨¡å¼
        return True

    def _execute_feature_task(self, task: Dict) -> bool:
        """æ‰§è¡ŒåŠŸèƒ½å¼€å‘ä»»åŠ¡"""
        self.logger.info("CONTROLLER", f"å¼€å§‹æ‰§è¡ŒåŠŸèƒ½å¼€å‘ä»»åŠ¡: {task['id']}")
        # åŠŸèƒ½å¼€å‘ä»»åŠ¡ç›®å‰ä½¿ç”¨ç®€åŒ–å®ç°
        # TODO: å¯ä»¥æ‰©å±•ä¸ºä¸‰è½®åä½œæ¨¡å¼
        return True

    def _execute_generic_task(self, task: Dict) -> bool:
        """æ‰§è¡Œé€šç”¨ä»»åŠ¡"""
        self.logger.info("CONTROLLER", f"æ‰§è¡Œé€šç”¨ä»»åŠ¡: {task['id']} - {task['title']}")

        # å¯¹äºé€šç”¨ä»»åŠ¡ï¼Œå°è¯•æ ¹æ®æè¿°åˆ¤æ–­ç±»å‹
        description = task.get("description", "").lower()
        title = task.get("title", "").lower()

        # å¦‚æœåŒ…å«"ä¿®å¤"ã€"bug"ã€"é”™è¯¯"ç­‰å…³é”®è¯ï¼ŒæŒ‰ bugfix å¤„ç†
        if any(keyword in description or keyword in title
               for keyword in ["ä¿®å¤", "fix", "bug", "é”™è¯¯", "error", "å¼‚å¸¸", "å¼‚å¸¸"]):
            self.logger.info("CONTROLLER", "è¯†åˆ«ä¸º Bug ä¿®å¤ä»»åŠ¡")
            return self._execute_bugfix_task(task)

        # å¦‚æœåŒ…å«"å®ç°"ã€"æ·»åŠ "ã€"æ–°åŠŸèƒ½"ã€"å¼€å‘"ç­‰å…³é”®è¯ï¼ŒæŒ‰ feature å¤„ç†
        if any(keyword in description or keyword in title
               for keyword in ["å®ç°", "æ·»åŠ ", "æ–°åŠŸèƒ½", "å¼€å‘", "develop", "feature", "æ–°å¢"]):
            self.logger.info("CONTROLLER", "è¯†åˆ«ä¸ºåŠŸèƒ½å¼€å‘ä»»åŠ¡")
            return self._execute_feature_task(task)

        # é»˜è®¤ï¼šè®°å½•æ—¥å¿—ï¼Œè¿”å› Falseï¼ˆéœ€è¦æ‰‹åŠ¨å¤„ç†ï¼‰
        self.logger.warning(
            "CONTROLLER",
            f"é€šç”¨ä»»åŠ¡ç±»å‹æœªæ˜ç¡®ï¼Œæ— æ³•è‡ªåŠ¨æ‰§è¡Œ: {task['title']}"
        )

        return False

    def run(self, max_iterations: int = 10):
        """è¿è¡Œä¸»å¾ªç¯"""
        self.logger.info("CONTROLLER", f"å¯åŠ¨è‡ªä¸»ç¼–ç¨‹ä¸»å¾ªç¯")

        iteration = 0
        while iteration < max_iterations:
            iteration += 1
            self.logger.info("CONTROLLER", f"=== è¿­ä»£ {iteration}/{max_iterations} ===")

            # è·å–å¾…å¤„ç†ä»»åŠ¡
            pending_tasks = self.task_manager.get_pending_tasks(limit=3)

            if not pending_tasks:
                self.logger.success("CONTROLLER", "æ²¡æœ‰å¾…å¤„ç†ä»»åŠ¡ï¼Œé€€å‡ºå¾ªç¯")
                break

            # æ‰§è¡Œä»»åŠ¡
            for task in pending_tasks:
                task_id = task["id"]
                self.logger.info("CONTROLLER", f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task_id}")

                # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿›è¡Œä¸­
                self.task_manager.update_task_status(
                    task_id,
                    TaskStatus.IN_PROGRESS
                )

                # æ‰§è¡Œä»»åŠ¡
                success = self.execute_task(task)

                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                if success:
                    self.task_manager.update_task_status(
                        task_id,
                        TaskStatus.DONE
                    )
                    self.logger.success("CONTROLLER", f"ä»»åŠ¡å®Œæˆ: {task_id}")
                else:
                    self.task_manager.update_task_status(
                        task_id,
                        TaskStatus.FAILED,
                        error="ä»»åŠ¡æ‰§è¡Œå¤±è´¥"
                    )
                    self.logger.error("CONTROLLER", f"ä»»åŠ¡å¤±è´¥: {task_id}")

        self.logger.success("CONTROLLER", f"è‡ªä¸»ç¼–ç¨‹ä¸»å¾ªç¯å®Œæˆï¼Œå…±å¤„ç† {iteration} æ¬¡è¿­ä»£")


def main():
    """ä¸»å‡½æ•°"""
    import sys

    controller = AutonomousController()

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        command = sys.argv[1]

        if command == "run":
            # è¿è¡Œä¸»å¾ªç¯
            controller.run()
        elif command == "test":
            # è¿è¡Œæµ‹è¯•
            controller.logger.info("CONTROLLER", "è¿è¡Œæµ‹è¯•æ¨¡å¼")

            # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
            test_task = Task(
                id=controller.generate_task_id(),
                title="æµ‹è¯•ä»»åŠ¡",
                description="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ä»»åŠ¡",
                source="manual",
                type=TaskType.MAINTENANCE,
                priority="medium",
                status=TaskStatus.PENDING,
                created_at=datetime.now().isoformat()
            )

            controller.task_manager.add_task(test_task)
            controller.logger.success("CONTROLLER", "æµ‹è¯•ä»»åŠ¡å·²åˆ›å»º")
        else:
            print(f"æœªçŸ¥å‘½ä»¤: {command}")
            print("ç”¨æ³•: python autonomous_controller_v3.py [run|test]")
            sys.exit(1)
    else:
        # é»˜è®¤è¿è¡Œä¸»å¾ªç¯
        controller.run()


if __name__ == "__main__":
    main()
