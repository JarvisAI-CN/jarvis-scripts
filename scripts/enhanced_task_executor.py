#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºçš„ä»»åŠ¡æ‰§è¡Œå™¨ - Enhanced Task Executor
å®ç°è‡ªä¸»ç¼–ç¨‹é¡¹ç›®çš„ä¸‰å¤§å¢å¼ºåŠŸèƒ½

æ ¸å¿ƒåŠŸèƒ½:
1. ä¿®å¤ä»»åŠ¡å¾ªç¯é—®é¢˜ - æ”¹è¿›ä»»åŠ¡ç±»å‹æ£€æµ‹é€»è¾‘
2. å¢å¼ºç›‘æ§ä»»åŠ¡ - Gateway/WebDAV/é˜ˆå€¼æ£€æŸ¥ + é£ä¹¦å‘Šè­¦
3. å¢å¼ºçŸ¥è¯†ç®¡ç† - PARAç´¢å¼• + ObsidianåŒé“¾ + çŸ¥è¯†å›¾è°±
"""

import os
import sys
import json
import subprocess
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple

# å¯¼å…¥é¡¹ç›®æ¨¡å—
scripts_dir = Path(__file__).parent
if str(scripts_dir) not in sys.path:
    sys.path.insert(0, str(scripts_dir))

try:
    from modules.feishu_notifier import FeishuNotifier
    import todo_to_tasklist
except ImportError as e:
    print(f"è­¦å‘Š: æ¨¡å—å¯¼å…¥å¤±è´¥ - {e}")
    FeishuNotifier = None
    todo_to_tasklist = None

# é…ç½®
WORKSPACE = Path("/home/ubuntu/.openclaw/workspace")
LOG_DIR = WORKSPACE / "logs"
HEALTH_CHECK_SCRIPT = scripts_dir / "modules" / "health_checks.sh"


class EnhancedTaskExecutor:
    """å¢å¼ºçš„ä»»åŠ¡æ‰§è¡Œå™¨"""
    
    def __init__(self, logger=None):
        self.workspace = WORKSPACE
        self.logger = logger
        
        # åˆå§‹åŒ–é£ä¹¦é€šçŸ¥å™¨
        if FeishuNotifier:
            try:
                self.feishu = FeishuNotifier()
            except Exception as e:
                self.logger.warning(f"é£ä¹¦é€šçŸ¥å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.feishu = None
        else:
            self.feishu = None
    
    def log(self, level: str, module: str, message: str):
        """æ—¥å¿—è®°å½•"""
        if self.logger:
            if level == "INFO":
                self.logger.info(module, message)
            elif level == "SUCCESS":
                self.logger.success(module, message)
            elif level == "ERROR":
                self.logger.error(module, message)
            elif level == "WARNING":
                self.logger.warning(module, message)
        else:
            print(f"[{level}] [{module}] {message}")
    
    def check_gateway_status(self) -> Tuple[bool, str]:
        """æ£€æŸ¥GatewayçŠ¶æ€"""
        try:
            result = subprocess.run(
                ["openclaw", "status", "--json"],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                status_data = json.loads(result.stdout)
                
                # æ£€æŸ¥Gatewayæ˜¯å¦running
                gateway = status_data.get("gateway", {})
                if "running" not in gateway.get("state", ""):
                    return False, "Gatewayæœªè¿è¡Œ"
                
                return True, f"Gatewayè¿è¡Œæ­£å¸¸ - {gateway.get('state', '')}"
            else:
                return False, f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {result.stderr}"
                
        except subprocess.TimeoutExpired:
            return False, "GatewayçŠ¶æ€æ£€æŸ¥è¶…æ—¶"
        except Exception as e:
            return False, f"GatewayçŠ¶æ€æ£€æŸ¥å¼‚å¸¸: {str(e)}"
    
    def check_webdav_response_time(self) -> Tuple[bool, float, str]:
        """æ£€æŸ¥WebDAVå“åº”æ—¶é—´"""
        try:
            start = datetime.now()
            
            # æµ‹è¯•123ç›˜æŒ‚è½½ç‚¹
            test_file = self.workspace / "123pan" / ".test_write.tmp"
            
            # å†™å…¥æµ‹è¯•
            with open(test_file, "w") as f:
                f.write("test")
            
            # è¯»å–æµ‹è¯•
            with open(test_file, "r") as f:
                f.read()
            
            # åˆ é™¤æµ‹è¯•æ–‡ä»¶
            test_file.unlink()
            
            elapsed = (datetime.now() - start).total_seconds()
            
            if elapsed > 5.0:
                return False, elapsed, f"WebDAVå“åº”è¿‡æ…¢: {elapsed:.2f}ç§’"
            else:
                return True, elapsed, f"WebDAVå“åº”æ­£å¸¸: {elapsed:.2f}ç§’"
                
        except Exception as e:
            elapsed = (datetime.now() - start).total_seconds()
            return False, elapsed, f"WebDAVæ£€æŸ¥å¤±è´¥: {str(e)}"
    
    def check_alert_thresholds(self, metrics: Dict) -> List[Dict]:
        """æ£€æŸ¥å‘Šè­¦é˜ˆå€¼"""
        alerts = []
        
        # GatewayçŠ¶æ€å‘Šè­¦
        if not metrics.get("gateway_ok", False):
            alerts.append({
                "type": "critical",
                "source": "gateway",
                "message": metrics.get("gateway_status", "Gatewayå¼‚å¸¸")
            })
        
        # WebDAVå“åº”æ—¶é—´å‘Šè­¦
        webdav_time = metrics.get("webdav_response_time", 0)
        if webdav_time > 5.0:
            alerts.append({
                "type": "warning",
                "source": "webdav",
                "message": f"WebDAVå“åº”æ—¶é—´è¿‡é•¿: {webdav_time:.2f}ç§’"
            })
        
        # ç£ç›˜ç©ºé—´å‘Šè­¦
        disk_usage = metrics.get("disk_usage_percent", 0)
        if disk_usage > 80:
            alerts.append({
                "type": "warning",
                "source": "disk",
                "message": f"ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {disk_usage}%"
            })
        
        return alerts
    
    def send_feishu_alert(self, alerts: List[Dict]) -> bool:
        """å‘é€é£ä¹¦å‘Šè­¦é€šçŸ¥"""
        if not self.feishu:
            self.log("WARNING", "ENHANCED_EXECUTOR", "é£ä¹¦é€šçŸ¥å™¨ä¸å¯ç”¨")
            return False
        
        if not alerts:
            return True
        
        # æ„å»ºå‘Šè­¦æ¶ˆæ¯
        critical_alerts = [a for a in alerts if a["type"] == "critical"]
        warning_alerts = [a for a in alerts if a["type"] == "warning"]
        
        message_parts = ["ğŸš¨ **ç³»ç»Ÿç›‘æ§å‘Šè­¦**\n"]
        
        if critical_alerts:
            message_parts.append("### ğŸ”´ ä¸¥é‡å‘Šè­¦\n")
            for alert in critical_alerts:
                message_parts.append(f"- **{alert['source']}**: {alert['message']}\n")
        
        if warning_alerts:
            message_parts.append("### âš ï¸ è­¦å‘Š\n")
            for alert in warning_alerts:
                message_parts.append(f"- **{alert['source']}**: {alert['message']}\n")
        
        message = "".join(message_parts)
        
        try:
            result = self.feishu.send_message(message)
            if result:
                self.log("SUCCESS", "ENHANCED_EXECUTOR", "é£ä¹¦å‘Šè­¦å·²å‘é€")
                return True
            else:
                self.log("ERROR", "ENHANCED_EXECUTOR", "é£ä¹¦å‘Šè­¦å‘é€å¤±è´¥")
                return False
        except Exception as e:
            self.log("ERROR", "ENHANCED_EXECUTOR", f"é£ä¹¦å‘Šè­¦å¼‚å¸¸: {str(e)}")
            return False
    
    def execute_enhanced_monitoring(self, task: Dict) -> bool:
        """æ‰§è¡Œå¢å¼ºçš„ç›‘æ§ä»»åŠ¡"""
        task_id = task.get("id")
        self.log("INFO", "ENHANCED_EXECUTOR", f"å¼€å§‹å¢å¼ºç›‘æ§ä»»åŠ¡: {task_id}")
        
        try:
            # 1. æ£€æŸ¥GatewayçŠ¶æ€
            gateway_ok, gateway_status = self.check_gateway_status()
            self.log("INFO", "ENHANCED_EXECUTOR", f"Gatewayæ£€æŸ¥: {gateway_status}")
            
            # 2. æ£€æŸ¥WebDAVå“åº”æ—¶é—´
            webdav_ok, webdav_time, webdav_status = self.check_webdav_response_time()
            self.log("INFO", "ENHANCED_EXECUTOR", f"WebDAVæ£€æŸ¥: {webdav_status}")
            
            # 3. æ£€æŸ¥ç£ç›˜ç©ºé—´
            df_result = subprocess.run(
                ["df", "/home/ubuntu/123pan"],
                capture_output=True,
                text=True
            )
            disk_usage_line = df_result.stdout.split('\n')[1].split()
            disk_usage_percent = int(disk_usage_line[4].rstrip('%'))
            
            # 4. æ±‡æ€»æŒ‡æ ‡
            metrics = {
                "gateway_ok": gateway_ok,
                "gateway_status": gateway_status,
                "webdav_ok": webdav_ok,
                "webdav_response_time": webdav_time,
                "disk_usage_percent": disk_usage_percent,
                "timestamp": datetime.now().isoformat()
            }
            
            # 5. æ£€æŸ¥å‘Šè­¦é˜ˆå€¼
            alerts = self.check_alert_thresholds(metrics)
            
            # 6. å‘é€é£ä¹¦å‘Šè­¦ï¼ˆå¦‚æœ‰ï¼‰
            if alerts:
                self.send_feishu_alert(alerts)
            
            # 7. ä¿å­˜ç›‘æ§æ—¥å¿—
            monitor_log = LOG_DIR / "enhanced_monitoring.jsonl"
            with open(monitor_log, "a") as f:
                f.write(json.dumps(metrics) + "\n")
            
            self.log("SUCCESS", "ENHANCED_EXECUTOR", f"å¢å¼ºç›‘æ§ä»»åŠ¡å®Œæˆ: {task_id}")
            return True
            
        except Exception as e:
            self.log("ERROR", "ENHANCED_EXECUTOR", f"å¢å¼ºç›‘æ§ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False
    
    def scan_para_resources(self) -> List[Dict]:
        """æ‰«æPARA/Resourcesç›®å½•"""
        resources_dir = self.workspace / "PARA" / "Resources"
        if not resources_dir.exists():
            self.log("WARNING", "ENHANCED_EXECUTOR", "PARA/Resourcesç›®å½•ä¸å­˜åœ¨")
            return []
        
        resources = []
        for item in resources_dir.iterdir():
            if item.is_file() and item.suffix in ['.md', '.txt']:
                resources.append({
                    "path": str(item),
                    "name": item.name,
                    "size": item.stat().st_size,
                    "modified": datetime.fromtimestamp(item.stat().st_mtime).isoformat()
                })
        
        return resources
    
    def detect_obsidian_broken_links(self, file_path: Path) -> List[str]:
        """æ£€æµ‹Obsidianæ–­è£‚çš„åŒé“¾"""
        broken_links = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾æ‰€æœ‰[[wikilinks]]
            import re
            pattern = r'\[\[([^\]]+)\]\]'
            links = re.findall(pattern, content)
            
            # æ£€æŸ¥æ¯ä¸ªé“¾æ¥çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            for link in links:
                # æ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„
                potential_paths = [
                    self.workspace / f"{link}.md",
                    self.workspace / "PARA" / "Resources" / f"{link}.md",
                    self.workspace / "Zettelkasten" / f"{link}.md",
                ]
                
                exists = any(p.exists() for p in potential_paths)
                if not exists:
                    broken_links.append(link)
        
        except Exception as e:
            self.log("WARNING", "ENHANCED_EXECUTOR", f"æ£€æµ‹åŒé“¾å¤±è´¥: {str(e)}")
        
        return broken_links
    
    def build_knowledge_graph_index(self) -> Dict:
        """æ„å»ºçŸ¥è¯†å›¾è°±ç´¢å¼•"""
        index = {
            "nodes": [],
            "edges": [],
            "generated_at": datetime.now().isoformat()
        }
        
        # æ‰«ææ‰€æœ‰Markdownæ–‡ä»¶
        for md_file in self.workspace.rglob("*.md"):
            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æå–åŒé“¾
                import re
                links = re.findall(r'\[\[([^\]]+)\]\]', content)
                
                # æ·»åŠ èŠ‚ç‚¹
                node_id = str(md_file.relative_to(self.workspace))
                index["nodes"].append({
                    "id": node_id,
                    "name": md_file.stem,
                    "path": str(md_file),
                    "link_count": len(links)
                })
                
                # æ·»åŠ è¾¹
                for link in links:
                    index["edges"].append({
                        "from": node_id,
                        "to": link,
                        "type": "wikilink"
                    })
            
            except Exception as e:
                continue  # è·³è¿‡æ— æ³•è¯»å–çš„æ–‡ä»¶
        
        return index
    
    def execute_enhanced_knowledge(self, task: Dict) -> bool:
        """æ‰§è¡Œå¢å¼ºçš„çŸ¥è¯†ç®¡ç†ä»»åŠ¡"""
        task_id = task.get("id")
        self.log("INFO", "ENHANCED_EXECUTOR", f"å¼€å§‹å¢å¼ºçŸ¥è¯†ç®¡ç†ä»»åŠ¡: {task_id}")
        
        try:
            results = {
                "task_id": task_id,
                "started_at": datetime.now().isoformat()
            }
            
            # 1. PARAç³»ç»Ÿç´¢å¼•
            resources = self.scan_para_resources()
            results["para_resources_count"] = len(resources)
            self.log("INFO", "ENHANCED_EXECUTOR", f"æ‰«æåˆ° {len(resources)} ä¸ªèµ„æºæ–‡ä»¶")
            
            # 2. ObsidianåŒé“¾ä¼˜åŒ–æ£€æµ‹
            broken_links_count = 0
            checked_files = 0
            
            for md_file in self.workspace.rglob("*.md"):
                if checked_files >= 50:  # é™åˆ¶æ£€æŸ¥æ•°é‡
                    break
                
                broken = self.detect_obsidian_broken_links(md_file)
                if broken:
                    broken_links_count += len(broken)
                
                checked_files += 1
            
            results["obsidian_checked_files"] = checked_files
            results["obsidian_broken_links"] = broken_links_count
            self.log("INFO", "ENHANCED_EXECUTOR", f"æ£€æŸ¥äº† {checked_files} ä¸ªæ–‡ä»¶ï¼Œå‘ç° {broken_links_count} ä¸ªæ–­è£‚é“¾æ¥")
            
            # 3. çŸ¥è¯†å›¾è°±æ›´æ–°
            knowledge_graph = self.build_knowledge_graph_index()
            graph_file = LOG_DIR / "knowledge_graph.json"
            with open(graph_file, 'w') as f:
                json.dump(knowledge_graph, f, indent=2, ensure_ascii=False)
            
            results["knowledge_graph_nodes"] = len(knowledge_graph["nodes"])
            results["knowledge_graph_edges"] = len(knowledge_graph["edges"])
            self.log("INFO", "ENHANCED_EXECUTOR", f"çŸ¥è¯†å›¾è°±å·²æ›´æ–°: {len(knowledge_graph['nodes'])} ä¸ªèŠ‚ç‚¹ï¼Œ{len(knowledge_graph['edges'])} æ¡è¾¹")
            
            results["completed_at"] = datetime.now().isoformat()
            results["status"] = "completed"
            
            # ä¿å­˜ç»“æœ
            result_file = LOG_DIR / f"knowledge_task_{task_id}.json"
            with open(result_file, 'w') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            self.log("SUCCESS", "ENHANCED_EXECUTOR", f"å¢å¼ºçŸ¥è¯†ç®¡ç†ä»»åŠ¡å®Œæˆ: {task_id}")
            return True
            
        except Exception as e:
            self.log("ERROR", "ENHANCED_EXECUTOR", f"å¢å¼ºçŸ¥è¯†ç®¡ç†ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False


def main():
    """æµ‹è¯•å¢å¼ºä»»åŠ¡æ‰§è¡Œå™¨"""
    import logging as logging_module
    
    # é…ç½®æ—¥å¿—
    logging_module.basicConfig(level=logging_module.INFO)
    
    # åˆ›å»ºç®€å•æ—¥å¿—è®°å½•å™¨
    class SimpleLogger:
        def info(self, module, message):
            logging_module.info(f"[{module}] {message}")
        def success(self, module, message):
            logging_module.info(f"[{module}] âœ… {message}")
        def warning(self, module, message):
            logging_module.warning(f"[{module}] âš ï¸ {message}")
        def error(self, module, message):
            logging_module.error(f"[{module}] âŒ {message}")
    
    logger = SimpleLogger()
    executor = EnhancedTaskExecutor(logger=logger)
    
    print("æµ‹è¯•å¢å¼ºä»»åŠ¡æ‰§è¡Œå™¨\n")
    
    # æµ‹è¯•1: å¢å¼ºç›‘æ§
    print("=" * 50)
    print("æµ‹è¯•1: å¢å¼ºç›‘æ§ä»»åŠ¡")
    print("=" * 50)
    monitor_task = {
        "id": "TEST-001",
        "type": "monitoring",
        "title": "æµ‹è¯•ç›‘æ§ä»»åŠ¡"
    }
    result1 = executor.execute_enhanced_monitoring(monitor_task)
    print(f"ç»“æœ: {'æˆåŠŸ' if result1 else 'å¤±è´¥'}\n")
    
    # æµ‹è¯•2: å¢å¼ºçŸ¥è¯†ç®¡ç†
    print("=" * 50)
    print("æµ‹è¯•2: å¢å¼ºçŸ¥è¯†ç®¡ç†ä»»åŠ¡")
    print("=" * 50)
    knowledge_task = {
        "id": "TEST-002",
        "type": "knowledge",
        "title": "æµ‹è¯•çŸ¥è¯†ç®¡ç†ä»»åŠ¡"
    }
    result2 = executor.execute_enhanced_knowledge(knowledge_task)
    print(f"ç»“æœ: {'æˆåŠŸ' if result2 else 'å¤±è´¥'}\n")
    
    print("æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main()
