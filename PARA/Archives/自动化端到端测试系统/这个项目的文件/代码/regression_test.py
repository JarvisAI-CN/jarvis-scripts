#!/usr/bin/env python3
"""
å›å½’æµ‹è¯•æ¨¡å—

æä¾›åŠŸèƒ½éªŒè¯ã€å…¼å®¹æ€§æµ‹è¯•å’Œæµ‹è¯•å¥—ä»¶ç»„è£…èƒ½åŠ›ã€‚

æ ¸å¿ƒç»„ä»¶:
- FunctionalTest: é€šç”¨åŠŸèƒ½éªŒè¯ï¼ˆå‡½æ•°è¾“å‡ºã€æ¥å£å“åº”ã€æ–‡ä»¶å†…å®¹ï¼‰
- CompatibilityTest: å¤šé…ç½®å…¼å®¹æ€§éªŒè¯
- RegressionSuite: æµ‹è¯•å¥—ä»¶ç»„è£…å’Œæ‰¹é‡æ‰§è¡Œ

ç‰ˆæœ¬: v1.0
åˆ›å»º: 2026-02-15
"""

from __future__ import annotations
import json
import hashlib
import http.client
import urllib.request
import urllib.error
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional, Tuple, Union
from dataclasses import dataclass

from test_framework import TestCase, TestStatus, logger


@dataclass
class ValidationResult:
    """éªŒè¯ç»“æœæ•°æ®ç±»"""
    is_valid: bool
    expected: Any
    actual: Any
    message: str = ""

    def to_dict(self) -> Dict[str, Any]:
        return {
            "valid": self.is_valid,
            "expected": str(self.expected)[:200],  # é™åˆ¶é•¿åº¦
            "actual": str(self.actual)[:200],
            "message": self.message
        }


class FunctionalTest(TestCase):
    """
    åŠŸèƒ½éªŒè¯æµ‹è¯•ç”¨ä¾‹

    æ”¯æŒå¤šç§éªŒè¯ç±»å‹:
    1. å‡½æ•°è¾“å‡ºéªŒè¯ - æ‰§è¡Œå‡½æ•°å¹¶éªŒè¯è¿”å›å€¼
    2. æ¥å£å“åº”éªŒè¯ - HTTPè¯·æ±‚å¹¶éªŒè¯å“åº”
    3. æ–‡ä»¶å†…å®¹éªŒè¯ - æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§å’Œå†…å®¹

    ä½¿ç”¨ç¤ºä¾‹:
        # å‡½æ•°éªŒè¯
        def add(a, b):
            return a + b
        test = FunctionalTest.verify_function("add_test", add, args=(1, 2), expected=3)

        # æ¥å£éªŒè¯
        test = FunctionalTest.verify_api("api_test", "https://api.example.com/users", expected_status=200)

        # æ–‡ä»¶éªŒè¯
        test = FunctionalTest.verify_file("file_test", "/path/to/file.txt", expected_content="Hello")
    """

    def __init__(self, name: str, timeout: float = 300.0):
        super().__init__(name, timeout)
        self.validation_result: Optional[ValidationResult] = None

    # ========== å·¥å‚æ–¹æ³•ï¼šåˆ›å»ºä¸åŒç±»å‹çš„æµ‹è¯• ==========

    @classmethod
    def verify_function(cls,
                        name: str,
                        func: Callable,
                        args: Tuple = (),
                        kwargs: Dict = None,
                        expected: Any = None,
                        validator: Optional[Callable[[Any], bool]] = None) -> 'FunctionalTest':
        """
        åˆ›å»ºå‡½æ•°éªŒè¯æµ‹è¯•

        Args:
            name: æµ‹è¯•åç§°
            func: è¦éªŒè¯çš„å‡½æ•°
            args: ä½ç½®å‚æ•°
            kwargs: å…³é”®å­—å‚æ•°
            expected: æœŸæœ›è¿”å›å€¼ï¼ˆä¸validatoräºŒé€‰ä¸€ï¼‰
            validator: è‡ªå®šä¹‰éªŒè¯å‡½æ•° (actual) -> bool

        Returns:
            FunctionalTest å®ä¾‹

        ç¤ºä¾‹:
            test = FunctionalTest.verify_function(
                "calculate_sum",
                lambda x, y: x + y,
                args=(10, 20),
                expected=30
            )
        """
        kwargs = kwargs or {}

        class _FunctionTest(cls):
            def setup(self):
                self.func = func
                self.args = args
                self.kwargs = kwargs
                self.expected = expected
                self.validator = validator

            def run_test(self):
                try:
                    # æ‰§è¡Œå‡½æ•°
                    result = self.func(*self.args, **self.kwargs)
                    logger.info(f"Function {func.__name__} returned: {result}")

                    # éªŒè¯ç»“æœ
                    if self.validator is not None:
                        is_valid = self.validator(result)
                        self.validation_result = ValidationResult(
                            is_valid=is_valid,
                            expected="validator condition",
                            actual=result,
                            message="Custom validation" if is_valid else "Custom validation failed"
                        )
                        self.assert_true(is_valid, f"Custom validation failed for result: {result}")
                    else:
                        is_valid = (result == self.expected)
                        self.validation_result = ValidationResult(
                            is_valid=is_valid,
                            expected=self.expected,
                            actual=result,
                            message="Values match" if is_valid else f"Expected {self.expected}, got {result}"
                        )
                        self.assert_equal(result, self.expected, f"Function returned unexpected value")

                except Exception as e:
                    logger.error(f"Function execution failed: {e}")
                    raise

        return _FunctionTest(name)

    @classmethod
    def verify_api(cls,
                   name: str,
                   url: str,
                   method: str = "GET",
                   expected_status: int = 200,
                   expected_content: Optional[str] = None,
                   expected_json_path: Optional[Tuple[str, Any]] = None,
                   headers: Dict = None,
                   timeout: int = 30) -> 'FunctionalTest':
        """
        åˆ›å»ºæ¥å£éªŒè¯æµ‹è¯•

        Args:
            name: æµ‹è¯•åç§°
            url: æ¥å£URL
            method: HTTPæ–¹æ³• (GET/POST/PUT/DELETE)
            expected_status: æœŸæœ›HTTPçŠ¶æ€ç 
            expected_content: æœŸæœ›å“åº”å†…å®¹ï¼ˆå­ä¸²åŒ¹é…ï¼‰
            expected_json_path: æœŸæœ›JSONå­—æ®µ (path, value) å¦‚ ("data.id", 123)
            headers: è¯·æ±‚å¤´
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´

        Returns:
            FunctionalTest å®ä¾‹

        ç¤ºä¾‹:
            test = FunctionalTest.verify_api(
                "user_api",
                "https://api.example.com/users/1",
                expected_status=200,
                expected_json_path=("data.name", "Alice")
            )
        """
        headers = headers or {}

        class _APITest(cls):
            def setup(self):
                self.url = url
                self.method = method.upper()
                self.expected_status = expected_status
                self.expected_content = expected_content
                self.expected_json_path = expected_json_path
                self.headers = headers
                self.timeout = timeout

            def run_test(self):
                try:
                    logger.info(f"Testing API: {self.method} {self.url}")

                    # å‘é€HTTPè¯·æ±‚
                    req = urllib.request.Request(
                        self.url,
                        method=self.method,
                        headers=self.headers
                    )

                    with urllib.request.urlopen(req, timeout=self.timeout) as response:
                        status_code = response.getcode()
                        response_body = response.read().decode('utf-8')
                        logger.info(f"API response status: {status_code}")

                        # éªŒè¯çŠ¶æ€ç 
                        self.assert_equal(status_code, self.expected_status,
                                        f"Unexpected status code")

                        # éªŒè¯å“åº”å†…å®¹
                        if self.expected_content:
                            self.assert_in(self.expected_content, response_body,
                                         f"Expected content not found in response")
                            logger.info(f"Content validation passed: '{self.expected_content}'")

                        # éªŒè¯JSONå­—æ®µ
                        if self.expected_json_path:
                            json_data = json.loads(response_body)
                            path, expected_value = self.expected_json_path
                            actual_value = self._get_json_path(json_data, path)
                            self.assert_equal(actual_value, expected_value,
                                            f"JSON path '{path}' mismatch")
                            logger.info(f"JSON validation passed: {path} = {actual_value}")

                        self.validation_result = ValidationResult(
                            is_valid=True,
                            expected=f"Status {self.expected_status}",
                            actual=f"Status {status_code}",
                            message="API validation passed"
                        )

                except urllib.error.HTTPError as e:
                    logger.error(f"HTTP error: {e.code} - {e.reason}")
                    raise AssertionError(f"HTTP error {e.code}: {e.reason}")
                except urllib.error.URLError as e:
                    logger.error(f"URL error: {e.reason}")
                    raise AssertionError(f"Connection failed: {e.reason}")
                except json.JSONDecodeError as e:
                    logger.error(f"JSON decode error: {e}")
                    raise AssertionError(f"Invalid JSON response: {e}")

            def _get_json_path(self, data: Dict, path: str) -> Any:
                """è·å–JSONåµŒå¥—è·¯å¾„çš„å€¼ (å¦‚ 'data.user.id')"""
                keys = path.split('.')
                value = data
                for key in keys:
                    if isinstance(value, dict):
                        value = value.get(key)
                    else:
                        raise ValueError(f"Invalid path '{path}', key '{key}' not found")
                return value

        return _APITest(name)

    @classmethod
    def verify_file(cls,
                    name: str,
                    file_path: Union[str, Path],
                    must_exist: bool = True,
                    expected_content: Optional[str] = None,
                    expected_pattern: Optional[str] = None,
                    min_size: int = 0) -> 'FunctionalTest':
        """
        åˆ›å»ºæ–‡ä»¶éªŒè¯æµ‹è¯•

        Args:
            name: æµ‹è¯•åç§°
            file_path: æ–‡ä»¶è·¯å¾„
            must_exist: æ–‡ä»¶å¿…é¡»å­˜åœ¨
            expected_content: æœŸæœ›æ–‡ä»¶å†…å®¹ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
            expected_pattern: æœŸæœ›å†…å®¹æ¨¡å¼ï¼ˆå­ä¸²/æ­£åˆ™ï¼‰
            min_size: æœ€å°æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰

        Returns:
            FunctionalTest å®ä¾‹

        ç¤ºä¾‹:
            test = FunctionalTest.verify_file(
                "config_file",
                "/etc/app/config.json",
                must_exist=True,
                expected_pattern='"version": "1.0"'
            )
        """
        file_path = Path(file_path)

        class _FileTest(cls):
            def setup(self):
                self.file_path = file_path
                self.must_exist = must_exist
                self.expected_content = expected_content
                self.expected_pattern = expected_pattern
                self.min_size = min_size

            def run_test(self):
                logger.info(f"Verifying file: {self.file_path}")

                # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
                if self.must_exist:
                    self.assert_true(self.file_path.exists(),
                                   f"File does not exist: {self.file_path}")
                    logger.info(f"File exists: {self.file_path}")
                elif not self.file_path.exists():
                    logger.info("File does not exist (as expected)")
                    self.validation_result = ValidationResult(
                        is_valid=True,
                        expected="file not exist",
                        actual="file not exist",
                        message="File absence validated"
                    )
                    return

                # è·å–æ–‡ä»¶ä¿¡æ¯
                file_size = self.file_path.stat().st_size
                logger.info(f"File size: {file_size} bytes")

                # éªŒè¯æ–‡ä»¶å¤§å°
                self.assert_true(file_size >= self.min_size,
                               f"File too small: {file_size} < {self.min_size}")

                # è¯»å–æ–‡ä»¶å†…å®¹
                content = self.file_path.read_text(encoding='utf-8')

                # éªŒè¯ç²¾ç¡®å†…å®¹
                if self.expected_content is not None:
                    is_valid = content == self.expected_content
                    self.assert_true(is_valid,
                                   f"File content mismatch")
                    logger.info("Content exact match validated")

                # éªŒè¯å†…å®¹æ¨¡å¼
                if self.expected_pattern:
                    self.assert_in(self.expected_pattern, content,
                                 f"Pattern not found in file")
                    logger.info(f"Pattern validated: '{self.expected_pattern}'")

                self.validation_result = ValidationResult(
                    is_valid=True,
                    expected=f"File exists, size>={self.min_size}",
                    actual=f"File exists, size={file_size}",
                    message="File validation passed"
                )

        return _FileTest(name)


class CompatibilityTest(TestCase):
    """
    å…¼å®¹æ€§æµ‹è¯•ç”¨ä¾‹

    åœ¨å¤šä¸ªé…ç½®ç¯å¢ƒä¸‹è¿è¡Œç›¸åŒæµ‹è¯•ï¼ŒéªŒè¯ç»“æœä¸€è‡´æ€§ã€‚

    åº”ç”¨åœºæ™¯:
    - å¤šç‰ˆæœ¬å…¼å®¹æ€§ï¼ˆPython 3.8, 3.9, 3.10ï¼‰
    - å¤šç¯å¢ƒå…¼å®¹æ€§ï¼ˆdev, staging, prodï¼‰
    - å¤šé…ç½®å…¼å®¹æ€§ï¼ˆä¸åŒå‚æ•°ç»„åˆï¼‰

    ä½¿ç”¨ç¤ºä¾‹:
        def test_logic(env):
            return env["value"] * 2

        test = CompatibilityTest.multi_config(
            "multi_env_test",
            test_logic,
            configs=[
                {"name": "env1", "value": 5},
                {"name": "env2", "value": 10},
            ],
            compare_results=True  # æ¯”è¾ƒå„ç¯å¢ƒç»“æœæ˜¯å¦ä¸€è‡´
        )
    """

    def __init__(self, name: str, timeout: float = 300.0):
        super().__init__(name, timeout)
        self.config_results: Dict[str, Any] = {}
        self.comparison_result: Optional[Dict[str, Any]] = None

    @classmethod
    def multi_config(cls,
                     name: str,
                     test_func: Callable,
                     configs: List[Dict[str, Any]],
                     config_key: str = "name",
                     compare_results: bool = False,
                     result_comparator: Optional[Callable[[Any, Any], bool]] = None) -> 'CompatibilityTest':
        """
        åˆ›å»ºå¤šé…ç½®å…¼å®¹æ€§æµ‹è¯•

        Args:
            name: æµ‹è¯•åç§°
            test_func: æµ‹è¯•å‡½æ•°ï¼Œæ¥æ”¶é…ç½®å­—å…¸ä½œä¸ºå‚æ•°
            configs: é…ç½®åˆ—è¡¨ï¼Œæ¯ä¸ªé…ç½®æ˜¯ä¸€ä¸ªå­—å…¸
            config_key: é…ç½®æ ‡è¯†é”®åï¼ˆç”¨äºç»“æœç´¢å¼•ï¼‰
            compare_results: æ˜¯å¦æ¯”è¾ƒå„é…ç½®ç»“æœ
            result_comparator: è‡ªå®šä¹‰ç»“æœæ¯”è¾ƒå‡½æ•° (result1, result2) -> bool

        Returns:
            CompatibilityTest å®ä¾‹

        ç¤ºä¾‹:
            def calculate(data):
                return data["a"] + data["b"]

            test = CompatibilityTest.multi_config(
                "addition_compatibility",
                calculate,
                configs=[
                    {"name": "test1", "a": 1, "b": 2},
                    {"name": "test2", "a": 10, "b": 20},
                    {"name": "test3", "a": 100, "b": 200},
                ],
                compare_results=False  # ä¸æ¯”è¾ƒç»“æœï¼ŒåªéªŒè¯éƒ½èƒ½æ‰§è¡Œ
            )
        """
        class _MultiConfigTest(cls):
            def setup(self):
                self.test_func = test_func
                self.configs = configs
                self.config_key = config_key
                self.compare_results = compare_results
                self.result_comparator = result_comparator

            def run_test(self):
                logger.info(f"Running compatibility test with {len(self.configs)} configs")

                results = {}
                all_passed = True

                # åœ¨æ¯ä¸ªé…ç½®ä¸‹è¿è¡Œæµ‹è¯•
                for idx, config in enumerate(self.configs):
                    config_name = config.get(self.config_key, f"config_{idx}")
                    logger.info(f"Testing config: {config_name}")

                    try:
                        result = self.test_func(config)
                        results[config_name] = {
                            "status": "passed",
                            "result": result,
                            "config": config
                        }
                        logger.info(f"Config '{config_name}' passed: {result}")
                    except Exception as e:
                        all_passed = False
                        results[config_name] = {
                            "status": "failed",
                            "error": str(e),
                            "config": config
                        }
                        logger.error(f"Config '{config_name}' failed: {e}")

                self.config_results = results

                # éªŒè¯æ‰€æœ‰é…ç½®éƒ½é€šè¿‡
                self.assert_true(all_passed,
                               f"Some configs failed: {[k for k, v in results.items() if v['status'] == 'failed']}")

                # æ¯”è¾ƒç»“æœ
                if self.compare_results:
                    self._compare_results(results)

                logger.info("All compatibility tests passed")

            def _compare_results(self, results: Dict[str, Any]) -> None:
                """æ¯”è¾ƒå„é…ç½®ç»“æœ"""
                logger.info("Comparing results across configs...")

                passed_results = {k: v for k, v in results.items() if v["status"] == "passed"}

                if len(passed_results) < 2:
                    logger.warning("Not enough passed results to compare")
                    return

                # è·å–ç¬¬ä¸€ä¸ªç»“æœä½œä¸ºåŸºå‡†
                first_key = next(iter(passed_results))
                reference_result = passed_results[first_key]["result"]

                comparison_details = []
                all_match = True

                for key, data in passed_results.items():
                    if key == first_key:
                        continue

                    current_result = data["result"]

                    # ä½¿ç”¨è‡ªå®šä¹‰æ¯”è¾ƒå™¨æˆ–é»˜è®¤æ¯”è¾ƒ
                    if self.result_comparator:
                        match = self.result_comparator(reference_result, current_result)
                    else:
                        match = (reference_result == current_result)

                    comparison_details.append({
                        "config": key,
                        "match": match,
                        "reference": str(reference_result)[:100],
                        "current": str(current_result)[:100]
                    })

                    if not match:
                        all_match = False
                        logger.warning(f"Result mismatch: {first_key} vs {key}")

                self.comparison_result = {
                    "all_match": all_match,
                    "reference_config": first_key,
                    "comparisons": comparison_details
                }

                # å¦‚æœè¦æ±‚æ¯”è¾ƒï¼Œåˆ™æ–­è¨€æ‰€æœ‰ç»“æœä¸€è‡´
                if all_match:
                    logger.info("All results match across configs")
                else:
                    self.assert_true(False, "Results differ across configs")

        return _MultiConfigTest(name)

    @classmethod
    def multi_version(cls,
                      name: str,
                      test_func: Callable,
                      versions: List[str],
                      version_executor: Callable[[str, Callable], Any]) -> 'CompatibilityTest':
        """
        åˆ›å»ºå¤šç‰ˆæœ¬å…¼å®¹æ€§æµ‹è¯•

        Args:
            name: æµ‹è¯•åç§°
            test_func: æµ‹è¯•å‡½æ•°
            versions: ç‰ˆæœ¬åˆ—è¡¨ (å¦‚ ["3.8", "3.9", "3.10"])
            version_executor: ç‰ˆæœ¬æ‰§è¡Œå™¨ (version, func) -> result

        Returns:
            CompatibilityTest å®ä¾‹

        ç¤ºä¾‹:
            def execute_python(version, func):
                # åœ¨æŒ‡å®šPythonç‰ˆæœ¬ä¸‹æ‰§è¡Œå‡½æ•°
                return subprocess.run(["python"+version, "-c", func])

            test = CompatibilityTest.multi_version(
                "python_version_test",
                lambda: print("Hello"),
                versions=["3.8", "3.9", "3.10"],
                version_executor=execute_python
            )
        """
        configs = [{"version": v} for v in versions]

        class _VersionTest(cls.multi_config(name, test_func, configs, config_key="version")):
            def setup(self):
                super().setup()
                self.version_executor = version_executor

            def run_test(self):
                logger.info(f"Testing across {len(self.configs)} Python versions")

                results = {}

                for config in self.configs:
                    version = config["version"]
                    logger.info(f"Testing Python {version}")

                    try:
                        result = self.version_executor(version, self.test_func)
                        results[f"python_{version}"] = {
                            "status": "passed",
                            "result": result
                        }
                    except Exception as e:
                        results[f"python_{version}"] = {
                            "status": "failed",
                            "error": str(e)
                        }

                self.config_results = results

                # éªŒè¯è‡³å°‘æœ‰ä¸€ä¸ªç‰ˆæœ¬é€šè¿‡
                passed_count = sum(1 for r in results.values() if r["status"] == "passed")
                self.assert_true(passed_count > 0,
                               f"No versions passed: {list(results.keys())}")

                logger.info(f"Multi-version test: {passed_count}/{len(versions)} passed")

        return _VersionTest(name)


class RegressionSuite:
    """
    å›å½’æµ‹è¯•å¥—ä»¶

    æä¾›ä¾¿æ·çš„æµ‹è¯•ç»„è£…å’Œæ‰¹é‡æ‰§è¡Œèƒ½åŠ›ã€‚

    ä½¿ç”¨ç¤ºä¾‹:
        suite = RegressionSuite("Daily Regression")

        # æ·»åŠ åŠŸèƒ½æµ‹è¯•
        suite.add_test(FunctionalTest.verify_function("test1", func, expected=42))

        # æ·»åŠ å…¼å®¹æ€§æµ‹è¯•
        suite.add_test(CompatibilityTest.multi_config("test2", func, configs=[...]))

        # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
        result = suite.run()
        suite.print_report()
    """

    def __init__(self, name: str, parallel: bool = True, max_workers: int = 4):
        """
        åˆå§‹åŒ–æµ‹è¯•å¥—ä»¶

        Args:
            name: å¥—ä»¶åç§°
            parallel: æ˜¯å¦å¹¶è¡Œæ‰§è¡Œ
            max_workers: æœ€å¤§å¹¶å‘æ•°
        """
        self.name = name
        self.parallel = parallel
        self.max_workers = max_workers
        self.tests: List[TestCase] = []
        self.categories: Dict[str, List[TestCase]] = {}

    def add_test(self, test: TestCase, category: str = "default") -> 'RegressionSuite':
        """
        æ·»åŠ å•ä¸ªæµ‹è¯•ç”¨ä¾‹

        Args:
            test: æµ‹è¯•ç”¨ä¾‹
            category: åˆ†ç±»æ ‡ç­¾

        Returns:
            self (æ”¯æŒé“¾å¼è°ƒç”¨)

        ç¤ºä¾‹:
            suite.add_test(test1, "smoke").add_test(test2, "functional")
        """
        self.tests.append(test)
        if category not in self.categories:
            self.categories[category] = []
        self.categories[category].append(test)
        logger.info(f"Added test '{test.name}' to category '{category}'")
        return self

    def add_tests(self, tests: List[TestCase], category: str = "default") -> 'RegressionSuite':
        """æ‰¹é‡æ·»åŠ æµ‹è¯•ç”¨ä¾‹"""
        for test in tests:
            self.add_test(test, category)
        return self

    def add_functional_tests(self, tests: List[FunctionalTest], category: str = "functional") -> 'RegressionSuite':
        """æ‰¹é‡æ·»åŠ åŠŸèƒ½æµ‹è¯•"""
        return self.add_tests(tests, category)

    def add_compatibility_tests(self, tests: List[CompatibilityTest], category: str = "compatibility") -> 'RegressionSuite':
        """æ‰¹é‡æ·»åŠ å…¼å®¹æ€§æµ‹è¯•"""
        return self.add_tests(tests, category)

    def get_tests_by_category(self, category: str) -> List[TestCase]:
        """è·å–æŒ‡å®šåˆ†ç±»çš„æ‰€æœ‰æµ‹è¯•"""
        return self.categories.get(category, [])

    def run(self) -> Any:
        """
        æ‰§è¡Œæµ‹è¯•å¥—ä»¶

        Returns:
            TestSuiteResult å¯¹è±¡
        """
        from test_framework import TestRunner

        logger.info(f"Running regression suite: {self.name}")
        logger.info(f"Total tests: {len(self.tests)}")
        logger.info(f"Categories: {list(self.categories.keys())}")

        runner = TestRunner(suite_name=self.name, max_workers=self.max_workers)
        runner.add_tests(self.tests)

        if self.parallel:
            result = runner.run_parallel()
        else:
            result = runner.run_sequential()

        return result

    def run_category(self, category: str) -> Any:
        """åªè¿è¡ŒæŒ‡å®šåˆ†ç±»çš„æµ‹è¯•"""
        tests = self.get_tests_by_category(category)
        if not tests:
            logger.warning(f"No tests found in category: {category}")
            return None

        logger.info(f"Running category: {category} ({len(tests)} tests)")

        from test_framework import TestRunner
        runner = TestRunner(suite_name=f"{self.name}_{category}", max_workers=self.max_workers)
        runner.add_tests(tests)

        if self.parallel:
            return runner.run_parallel()
        else:
            return runner.run_sequential()

    def print_report(self, result: Any) -> None:
        """æ‰“å°æµ‹è¯•æŠ¥å‘Š"""
        from test_framework import TestReporter

        reporter = TestReporter(result)
        reporter.to_console()

    def save_json_report(self, result: Any, output_path: Union[str, Path]) -> None:
        """ä¿å­˜JSONæŠ¥å‘Š"""
        from test_framework import TestReporter

        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        reporter = TestReporter(result)
        reporter.to_json(output_path)

    @staticmethod
    def create_smoke_suite(name: str = "SmokeTest") -> 'RegressionSuite':
        """åˆ›å»ºå†’çƒŸæµ‹è¯•å¥—ä»¶ï¼ˆå¿«é€ŸéªŒè¯æ ¸å¿ƒåŠŸèƒ½ï¼‰"""
        return RegressionSuite(name, parallel=True, max_workers=4)

    @staticmethod
    def create_full_suite(name: str = "FullRegression") -> 'RegressionSuite':
        """åˆ›å»ºå®Œæ•´å›å½’æµ‹è¯•å¥—ä»¶"""
        return RegressionSuite(name, parallel=True, max_workers=8)


# ========== æ¼”ç¤ºå’Œæµ‹è¯• ==========

def example_function(x: int, y: int) -> int:
    """ç¤ºä¾‹å‡½æ•°ï¼šè®¡ç®—ä¸¤ä¸ªæ•°çš„å’Œ"""
    return x + y


def example_api_handler(config: Dict) -> Dict:
    """ç¤ºä¾‹APIå¤„ç†å™¨ï¼šæ¨¡æ‹ŸAPIå“åº”"""
    return {
        "status": "success",
        "data": {
            "id": config.get("id", 1),
            "name": config.get("name", "unknown"),
            "value": config.get("value", 0)
        }
    }


def demo_functional_tests():
    """æ¼”ç¤ºåŠŸèƒ½æµ‹è¯•"""
    print("\n" + "="*70)
    print("ğŸ“‹ åŠŸèƒ½æµ‹è¯•æ¼”ç¤º (FunctionalTest)")
    print("="*70)

    suite = RegressionSuite("FunctionalDemo")

    # 1. å‡½æ•°éªŒè¯
    suite.add_test(
        FunctionalTest.verify_function(
            "addition_test",
            example_function,
            args=(10, 20),
            expected=30
        ),
        category="math"
    )

    # 2. å¸¦éªŒè¯å™¨çš„å‡½æ•°æµ‹è¯•
    suite.add_test(
        FunctionalTest.verify_function(
            "validator_test",
            lambda x: x * 2,
            args=(5,),
            validator=lambda result: result > 0
        ),
        category="math"
    )

    # 3. æ–‡ä»¶éªŒè¯ï¼ˆä½¿ç”¨å½“å‰æ–‡ä»¶ï¼‰
    suite.add_test(
        FunctionalTest.verify_file(
            "this_file_exists",
            __file__,
            must_exist=True,
            expected_pattern="class FunctionalTest"
        ),
        category="file"
    )

    # è¿è¡Œå¹¶æŠ¥å‘Š
    result = suite.run()
    suite.print_report(result)

    return result


def demo_compatibility_tests():
    """æ¼”ç¤ºå…¼å®¹æ€§æµ‹è¯•"""
    print("\n" + "="*70)
    print("ğŸ”„ å…¼å®¹æ€§æµ‹è¯•æ¼”ç¤º (CompatibilityTest)")
    print("="*70)

    # å®šä¹‰ä¸€ä¸ªæµ‹è¯•å‡½æ•°
    def calculate_metric(config):
        """è®¡ç®—æŒ‡æ ‡ï¼ˆæ¨¡æ‹Ÿä¸åŒé…ç½®ä¸‹çš„è®¡ç®—ï¼‰"""
        base = config.get("base", 10)
        multiplier = config.get("multiplier", 2)
        return base * multiplier

    # åˆ›å»ºå¤šé…ç½®æµ‹è¯•
    test = CompatibilityTest.multi_config(
        "multi_config_test",
        calculate_metric,
        configs=[
            {"name": "config_A", "base": 10, "multiplier": 2},
            {"name": "config_B", "base": 20, "multiplier": 2},
            {"name": "config_C", "base": 30, "multiplier": 2},
        ],
        compare_results=False  # ä¸æ¯”è¾ƒç»“æœï¼ˆå› ä¸ºæœŸæœ›ä¸åŒï¼‰
    )

    # æ‰§è¡Œæµ‹è¯•
    result = test.execute()

    print(f"\næµ‹è¯•ç»“æœ: {result.status.value}")
    print(f"è€—æ—¶: {result.duration:.3f}s")
    if hasattr(test, 'config_results'):
        print(f"\né…ç½®ç»“æœ:")
        for config_name, config_result in test.config_results.items():
            print(f"  - {config_name}: {config_result['status']}")

    return result


def demo_full_regression_suite():
    """æ¼”ç¤ºå®Œæ•´å›å½’æµ‹è¯•å¥—ä»¶"""
    print("\n" + "="*70)
    print("ğŸ§ª å®Œæ•´å›å½’æµ‹è¯•å¥—ä»¶æ¼”ç¤º")
    print("="*70)

    suite = RegressionSuite.create_full_suite("CompleteRegression")

    # æ·»åŠ åŠŸèƒ½æµ‹è¯•
    suite.add_functional_tests([
        FunctionalTest.verify_function("test1", example_function, args=(1, 2), expected=3),
        FunctionalTest.verify_function("test2", example_function, args=(100, 200), expected=300),
        FunctionalTest.verify_file("test3", __file__, must_exist=True),
    ])

    # æ·»åŠ å…¼å®¹æ€§æµ‹è¯•
    suite.add_compatibility_tests([
        CompatibilityTest.multi_config(
            "compat1",
            example_api_handler,
            configs=[
                {"name": "env1", "id": 1, "value": 100},
                {"name": "env2", "id": 2, "value": 200},
            ]
        )
    ])

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    result = suite.run()
    suite.print_report(result)

    # ä¿å­˜æŠ¥å‘Š
    report_path = Path(__file__).parent / "test_results" / f"regression_{result.start_time.strftime('%Y%m%d_%H%M%S')}.json"
    suite.save_json_report(result, report_path)
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    return result


if __name__ == "__main__":
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           å›å½’æµ‹è¯•æ¨¡å— (regression_test.py) æ¼”ç¤º                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    # è¿è¡Œå„ç±»æ¼”ç¤º
    demo_functional_tests()
    demo_compatibility_tests()
    demo_full_regression_suite()

    print("\n" + "="*70)
    print("âœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆ!")
    print("="*70)
