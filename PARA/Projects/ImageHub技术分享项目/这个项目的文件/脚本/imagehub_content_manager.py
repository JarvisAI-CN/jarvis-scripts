#!/usr/bin/env python3
"""
ImageHubè‡ªåŠ¨åŒ–å†…å®¹ç®¡ç†ç³»ç»Ÿ v2.0
åŠŸèƒ½ï¼šå®Œæ•´çš„å†…å®¹ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆåˆ›å»ºâ†’å‘å¸ƒâ†’éªŒè¯â†’è´¨é‡æ£€æŸ¥â†’æ¸…ç†ï¼‰
ç‰ˆæœ¬ï¼šv2.0
åˆ›å»ºï¼š2026-02-14
"""

import requests
import json
import time
import re
import hashlib
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from difflib import SequenceMatcher
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


class MoltbookAPI:
    """Moltbook APIå°è£…ç±»"""

    def __init__(self, api_key: str, base_url: str = "https://www.moltbook.com/api/v1"):
        self.api_key = api_key
        self.base_url = base_url
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

    def get_user_info(self, username: str) -> Optional[Dict]:
        """è·å–ç”¨æˆ·ä¿¡æ¯"""
        try:
            url = f"{self.base_url}/users/{username}"
            response = requests.get(url, headers=self.headers, timeout=10)
            if response.status_code == 200:
                return response.json()
            else:
                logger.error(f"è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: HTTP {response.status_code}")
                return None
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·ä¿¡æ¯å¼‚å¸¸: {e}")
            return None

    def get_user_posts(self, username: str = "JarvisAI-CN", limit: int = 50) -> List[Dict]:
        """è·å–ç”¨æˆ·çš„å¸–å­åˆ—è¡¨"""
        try:
            user_info = self.get_user_info(username)
            if not user_info:
                return []

            user_id = user_info.get("id")
            if not user_id:
                logger.error("æ— æ³•è·å–ç”¨æˆ·ID")
                return []

            url = f"{self.base_url}/users/{user_id}/posts"
            params = {"limit": limit}
            response = requests.get(url, headers=self.headers, params=params, timeout=10)

            if response.status_code == 200:
                data = response.json()
                return data.get("posts", [])
            else:
                logger.error(f"è·å–å¸–å­åˆ—è¡¨å¤±è´¥: HTTP {response.status_code}")
                return []
        except Exception as e:
            logger.error(f"è·å–å¸–å­åˆ—è¡¨å¼‚å¸¸: {e}")
            return []

    def get_post(self, post_id: str) -> Optional[Dict]:
        """è·å–å•ä¸ªå¸–å­è¯¦æƒ…"""
        try:
            url = f"{self.base_url}/posts/{post_id}"
            response = requests.get(url, headers=self.headers, timeout=10)
            if response.status_code == 200:
                return response.json()
            else:
                logger.error(f"è·å–å¸–å­å¤±è´¥: HTTP {response.status_code}")
                return None
        except Exception as e:
            logger.error(f"è·å–å¸–å­å¼‚å¸¸: {e}")
            return None

    def create_post(self, title: str, content: str, submolt: str = "general") -> Optional[str]:
        """åˆ›å»ºå¸–å­"""
        try:
            url = f"{self.base_url}/posts"
            payload = {
                "title": title,
                "content": content,
                "submolt": submolt
            }

            response = requests.post(url, headers=self.headers, json=payload, timeout=30)

            if response.status_code == 201:
                data = response.json()
                post_id = data.get("post", {}).get("id")
                logger.info(f"åˆ›å»ºå¸–å­æˆåŠŸ: {title[:50]}... (ID: {post_id})")
                return post_id
            else:
                logger.error(f"åˆ›å»ºå¸–å­å¤±è´¥: HTTP {response.status_code} - {response.text}")
                return None
        except Exception as e:
            logger.error(f"åˆ›å»ºå¸–å­å¼‚å¸¸: {e}")
            return None

    def verify_challenge(self, verification_code: str, answer: str) -> bool:
        """éªŒè¯æ•°å­¦æŒ‘æˆ˜"""
        try:
            url = f"{self.base_url}/verify"
            payload = {
                "verification_code": verification_code,
                "answer": answer
            }
            response = requests.post(url, headers=self.headers, json=payload, timeout=10)
            return response.status_code == 200
        except Exception as e:
            logger.error(f"éªŒè¯æŒ‘æˆ˜å¼‚å¸¸: {e}")
            return False

    def delete_post(self, post_id: str) -> bool:
        """åˆ é™¤å¸–å­"""
        try:
            url = f"{self.base_url}/posts/{post_id}"
            response = requests.delete(url, headers=self.headers, timeout=10)
            if response.status_code == 200:
                logger.info(f"åˆ é™¤å¸–å­æˆåŠŸ: {post_id}")
                return True
            else:
                logger.error(f"åˆ é™¤å¸–å­å¤±è´¥: HTTP {response.status_code}")
                return False
        except Exception as e:
            logger.error(f"åˆ é™¤å¸–å­å¼‚å¸¸: {e}")
            return False


class ContentQualityChecker:
    """å†…å®¹è´¨é‡æ£€æŸ¥å™¨"""

    def __init__(self, min_length: int = 200, max_similarity: float = 0.9):
        self.min_length = min_length
        self.max_similarity = max_similarity

    def check_length(self, content: str) -> Tuple[bool, str]:
        """æ£€æŸ¥å†…å®¹é•¿åº¦"""
        if len(content) < self.min_length:
            return False, f"å†…å®¹è¿‡çŸ­ï¼š{len(content)}å­—ç¬¦ï¼ˆè¦æ±‚è‡³å°‘{self.min_length}å­—ç¬¦ï¼‰"
        return True, "é•¿åº¦æ£€æŸ¥é€šè¿‡"

    def check_placeholder(self, content: str) -> Tuple[bool, str]:
        """æ£€æŸ¥å ä½ç¬¦"""
        placeholders = ["å¾…å‡†å¤‡", "å¾…è¡¥å……", "TBD", "TODO", "..."]
        for ph in placeholders:
            if ph in content:
                return False, f"åŒ…å«å ä½ç¬¦: {ph}"
        return True, "å ä½ç¬¦æ£€æŸ¥é€šè¿‡"

    def check_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦"""
        return SequenceMatcher(None, text1, text2).ratio()

    def get_content_hash(self, content: str) -> str:
        """è·å–å†…å®¹çš„å“ˆå¸Œå€¼"""
        return hashlib.md5(content.encode('utf-8')).hexdigest()

    def check_quality(self, title: str, content: str) -> Dict[str, Any]:
        """ç»¼åˆè´¨é‡æ£€æŸ¥"""
        results = {
            "title": title,
            "passed": True,
            "issues": [],
            "score": 0
        }

        # æ£€æŸ¥æ ‡é¢˜
        if len(title) < 10:
            results["issues"].append("æ ‡é¢˜è¿‡çŸ­")
            results["passed"] = False
        if len(title) > 100:
            results["issues"].append("æ ‡é¢˜è¿‡é•¿")
            results["passed"] = False

        # æ£€æŸ¥å†…å®¹é•¿åº¦
        length_ok, length_msg = self.check_length(content)
        if not length_ok:
            results["issues"].append(length_msg)
            results["passed"] = False
        else:
            results["score"] += 20

        # æ£€æŸ¥å ä½ç¬¦
        placeholder_ok, placeholder_msg = self.check_placeholder(content)
        if not placeholder_ok:
            results["issues"].append(placeholder_msg)
            results["passed"] = False
        else:
            results["score"] += 20

        # æ£€æŸ¥å†…å®¹ç»“æ„ï¼ˆæ˜¯å¦æœ‰æ ‡é¢˜ã€æ®µè½ï¼‰
        if "##" in content or "###" in content:
            results["score"] += 20

        # æ£€æŸ¥ä»£ç å—
        if "```" in content:
            results["score"] += 20

        # æ£€æŸ¥é“¾æ¥
        if "http" in content:
            results["score"] += 20

        return results


class DuplicateDetector:
    """é‡å¤å†…å®¹æ£€æµ‹å™¨"""

    def __init__(self, api: MoltbookAPI):
        self.api = api
        self.posts_cache: List[Dict] = []
        self.content_map: Dict[str, str] = {}  # hash -> post_id

    def load_posts(self, username: str = "JarvisAI-CN", limit: int = 50):
        """åŠ è½½ç”¨æˆ·çš„å¸–å­"""
        logger.info(f"åŠ è½½å¸–å­åˆ—è¡¨: {username}ï¼ˆæœ€å¤š{limit}ç¯‡ï¼‰")
        self.posts_cache = self.api.get_user_posts(username, limit)
        logger.info(f"åŠ è½½äº† {len(self.posts_cache)} ç¯‡å¸–å­")

        # æ„å»ºå†…å®¹å“ˆå¸Œæ˜ å°„
        self.content_map = {}
        for post in self.posts_cache:
            content = post.get("content", "")
            content_hash = hashlib.md5(content.encode('utf-8')).hexdigest()
            self.content_map[content_hash] = post.get("id")

        logger.info(f"æ„å»ºäº† {len(self.content_map)} ä¸ªå†…å®¹å“ˆå¸Œ")

    def find_duplicates(self) -> List[Dict[str, Any]]:
        """æŸ¥æ‰¾é‡å¤å†…å®¹"""
        duplicates = []
        seen_hashes = {}

        for post in self.posts_cache:
            post_id = post.get("id")
            content = post.get("content", "")
            title = post.get("title", "")
            content_hash = hashlib.md5(content.encode('utf-8')).hexdigest()

            if content_hash in seen_hashes:
                duplicates.append({
                    "post_id": post_id,
                    "original_id": seen_hashes[content_hash],
                    "title": title,
                    "content_length": len(content),
                    "duplicate_type": "exact_match"
                })
                logger.warning(f"å‘ç°é‡å¤: {post_id} == {seen_hashes[content_hash]}")
            else:
                seen_hashes[content_hash] = post_id

        return duplicates

    def find_similar_content(self, threshold: float = 0.95) -> List[Dict[str, Any]]:
        """æŸ¥æ‰¾ç›¸ä¼¼å†…å®¹ï¼ˆä½¿ç”¨ç›¸ä¼¼åº¦ç®—æ³•ï¼‰"""
        similar_pairs = []

        for i, post1 in enumerate(self.posts_cache):
            for post2 in self.posts_cache[i+1:]:
                content1 = post1.get("content", "")
                content2 = post2.get("content", "")
                title1 = post1.get("title", "")
                title2 = post2.get("title", "")

                similarity = SequenceMatcher(None, content1, content2).ratio()

                if similarity >= threshold:
                    similar_pairs.append({
                        "post1_id": post1.get("id"),
                        "post2_id": post2.get("id"),
                        "post1_title": title1,
                        "post2_title": title2,
                        "similarity": round(similarity * 100, 2),
                        "similarity_type": "high_similarity"
                    })
                    logger.warning(f"å‘ç°ç›¸ä¼¼å†…å®¹: {post1.get('id')} vs {post2.get('id')} ({similarity*100:.1f}%)")

        return similar_pairs

    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆé‡å¤æ£€æµ‹æŠ¥å‘Š"""
        duplicates = self.find_duplicates()
        similar = self.find_similar_content()

        return {
            "total_posts": len(self.posts_cache),
            "exact_duplicates": len(duplicates),
            "similar_content": len(similar),
            "duplicate_details": duplicates,
            "similar_details": similar,
            "timestamp": datetime.now().isoformat()
        }


class ContentManager:
    """å†…å®¹ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†å†…å®¹ç”Ÿå‘½å‘¨æœŸ"""

    def __init__(self, api_key: str):
        self.api = MoltbookAPI(api_key)
        self.quality_checker = ContentQualityChecker()
        self.duplicate_detector = DuplicateDetector(self.api)
        self.state_file = Path("/home/ubuntu/.openclaw/workspace/PARA/Projects/ImageHubæŠ€æœ¯åˆ†äº«é¡¹ç›®/è¿™ä¸ªé¡¹ç›®çš„æ–‡ä»¶/æ—¥å¿—/content_manager_state.json")

    def load_state(self) -> Dict:
        """åŠ è½½çŠ¶æ€"""
        if self.state_file.exists():
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"åŠ è½½çŠ¶æ€å¤±è´¥: {e}")
                return {}
        return {}

    def save_state(self, state: Dict):
        """ä¿å­˜çŠ¶æ€"""
        try:
            self.state_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.state_file, 'w', encoding='utf-8') as f:
                json.dump(state, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"ä¿å­˜çŠ¶æ€å¤±è´¥: {e}")

    def scan_and_clean(self, dry_run: bool = False) -> Dict[str, Any]:
        """æ‰«æå¹¶æ¸…ç†é‡å¤å†…å®¹"""
        logger.info("å¼€å§‹æ‰«æé‡å¤å†…å®¹...")

        # åŠ è½½å¸–å­
        self.duplicate_detector.load_posts()

        # ç”ŸæˆæŠ¥å‘Š
        report = self.duplicate_detector.generate_report()

        # æ¸…ç†é‡å¤å†…å®¹
        deleted_posts = []
        for duplicate in report["duplicate_details"]:
            post_id = duplicate["post_id"]
            original_id = duplicate["original_id"]

            logger.warning(f"å‘ç°é‡å¤: {post_id} (åŸå§‹: {original_id})")

            if not dry_run:
                if self.api.delete_post(post_id):
                    deleted_posts.append(post_id)
                else:
                    logger.error(f"åˆ é™¤å¤±è´¥: {post_id}")
            else:
                logger.info(f"[DRY RUN] å°†åˆ é™¤: {post_id}")

        report["deleted_posts"] = deleted_posts
        report["dry_run"] = dry_run

        return report

    def create_and_verify_post(
        self,
        title: str,
        content: str,
        submolt: str = "general",
        verify: bool = True
    ) -> Optional[Dict]:
        """åˆ›å»ºå¹¶éªŒè¯å¸–å­"""
        logger.info(f"åˆ›å»ºå¸–å­: {title[:50]}...")

        # è´¨é‡æ£€æŸ¥
        quality_result = self.quality_checker.check_quality(title, content)

        if not quality_result["passed"]:
            logger.error(f"è´¨é‡æ£€æŸ¥å¤±è´¥: {quality_result['issues']}")
            return None

        logger.info(f"è´¨é‡æ£€æŸ¥é€šè¿‡: {quality_result['score']}/100")

        # åˆ›å»ºå¸–å­
        post_id = self.api.create_post(title, content, submolt)

        if not post_id:
            logger.error("åˆ›å»ºå¸–å­å¤±è´¥")
            return None

        # éªŒè¯å¸–å­
        if verify:
            time.sleep(5)  # ç­‰å¾…APIæ›´æ–°

            post = self.api.get_post(post_id)
            if not post:
                logger.error(f"éªŒè¯å¤±è´¥: æ— æ³•è·å–å¸–å­ {post_id}")
                return None

            logger.info(f"éªŒè¯æˆåŠŸ: {post_id}")

            return {
                "post_id": post_id,
                "title": title,
                "content_length": len(content),
                "quality_score": quality_result["score"],
                "verified": True
            }

        return {"post_id": post_id}


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="ImageHubè‡ªåŠ¨åŒ–å†…å®¹ç®¡ç†ç³»ç»Ÿv2.0")
    parser.add_argument("command", choices=["scan", "clean", "check", "report"], help="å‘½ä»¤")
    parser.add_argument("--dry-run", action="store_true", help="å¹²è¿è¡Œï¼ˆä¸å®é™…åˆ é™¤ï¼‰")
    parser.add_argument("--threshold", type=float, default=0.95, help="ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰")
    parser.add_argument("--post-id", help="å¸–å­IDï¼ˆç”¨äºcheckå‘½ä»¤ï¼‰")

    args = parser.parse_args()

    # APIå¯†é’¥ï¼ˆä»PASSWORDS.mdè·å–ï¼‰
    api_key = "moltbook_sk_Lu4wGUciU8Pdk070fin4ngm1P4J736wL"

    # åˆ›å»ºç®¡ç†å™¨
    manager = ContentManager(api_key)

    if args.command == "scan":
        # æ‰«æé‡å¤å†…å®¹
        report = manager.scan_and_clean(dry_run=True)
        print(json.dumps(report, indent=2, ensure_ascii=False))

    elif args.command == "clean":
        # æ¸…ç†é‡å¤å†…å®¹
        report = manager.scan_and_clean(dry_run=args.dry_run)
        print(json.dumps(report, indent=2, ensure_ascii=False))

    elif args.command == "check":
        # æ£€æŸ¥å•ä¸ªå¸–å­è´¨é‡
        if not args.post_id:
            print("é”™è¯¯: --post-id å‚æ•°å¿…éœ€")
            return

        post = manager.api.get_post(args.post_id)
        if not post:
            print(f"é”™è¯¯: æ— æ³•è·å–å¸–å­ {args.post_id}")
            return

        quality = manager.quality_checker.check_quality(
            post.get("title", ""),
            post.get("content", "")
        )

        print(f"å¸–å­è´¨é‡æ£€æŸ¥ç»“æœ: {args.post_id}")
        print(json.dumps(quality, indent=2, ensure_ascii=False))

    elif args.command == "report":
        # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        manager.duplicate_detector.load_posts()
        report = manager.duplicate_detector.generate_report()

        print(f"\nğŸ“Š ImageHubå†…å®¹ç®¡ç†æŠ¥å‘Š")
        print(f"=" * 50)
        print(f"æ€»å¸–å­æ•°: {report['total_posts']}")
        print(f"å®Œå…¨é‡å¤: {report['exact_duplicates']}")
        print(f"é«˜åº¦ç›¸ä¼¼: {report['similar_content']}")
        print(f"ç”Ÿæˆæ—¶é—´: {report['timestamp']}")


if __name__ == "__main__":
    main()
